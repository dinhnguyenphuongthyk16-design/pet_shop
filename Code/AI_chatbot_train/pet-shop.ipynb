{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-14T14:47:39.441302Z",
     "iopub.status.busy": "2025-11-14T14:47:39.441053Z",
     "iopub.status.idle": "2025-11-14T14:47:43.744863Z",
     "shell.execute_reply": "2025-11-14T14:47:43.743598Z",
     "shell.execute_reply.started": "2025-11-14T14:47:39.441281Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DIR TREE] /kaggle/input\n",
      "input/\n",
      "    amazon-pet-supplies-data/\n",
      "        amazon_pet_supplies_dataset_sample.csv\n",
      "    chewy-data/\n",
      "        chewy_scraper_sample.csv\n",
      "    e-commerce-pet-supplies-dataset/\n",
      "        aliexpress_pet_supplies.csv\n",
      "    pet-food-customer-orders-online/\n",
      "        pet_food_customer_orders.csv\n",
      "    pet-store-records-2020/\n",
      "        pet_store_records_2020.csv\n",
      "    sales-data-shop-pet/\n",
      "        metrics_2023-01-01_to_2023-08-10_targeted_interest.csv\n",
      "    us-pet-food-supply-stores/\n",
      "        US Pet Food  Supply Stores.csv\n",
      "\n",
      "[INFO] Copying CSV ‚Üí OUTPUT\n",
      "       From: /kaggle/input/pet-store-records-2020/pet_store_records_2020.csv\n",
      "       To:   /kaggle/working/excel_csv/pet-store-records-2020/pet_store_records_2020.csv\n",
      "\n",
      "[INFO] Copying CSV ‚Üí OUTPUT\n",
      "       From: /kaggle/input/pet-food-customer-orders-online/pet_food_customer_orders.csv\n",
      "       To:   /kaggle/working/excel_csv/pet-food-customer-orders-online/pet_food_customer_orders.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Copying CSV ‚Üí OUTPUT\n",
      "       From: /kaggle/input/e-commerce-pet-supplies-dataset/aliexpress_pet_supplies.csv\n",
      "       To:   /kaggle/working/excel_csv/e-commerce-pet-supplies-dataset/aliexpress_pet_supplies.csv\n",
      "\n",
      "[INFO] Copying CSV ‚Üí OUTPUT\n",
      "       From: /kaggle/input/amazon-pet-supplies-data/amazon_pet_supplies_dataset_sample.csv\n",
      "       To:   /kaggle/working/excel_csv/amazon-pet-supplies-data/amazon_pet_supplies_dataset_sample.csv\n",
      "\n",
      "[INFO] Copying CSV ‚Üí OUTPUT\n",
      "       From: /kaggle/input/us-pet-food-supply-stores/US Pet Food  Supply Stores.csv\n",
      "       To:   /kaggle/working/excel_csv/us-pet-food-supply-stores/US Pet Food  Supply Stores.csv\n",
      "\n",
      "[INFO] Copying CSV ‚Üí OUTPUT\n",
      "       From: /kaggle/input/sales-data-shop-pet/metrics_2023-01-01_to_2023-08-10_targeted_interest.csv\n",
      "       To:   /kaggle/working/excel_csv/sales-data-shop-pet/metrics_2023-01-01_to_2023-08-10_targeted_interest.csv\n",
      "\n",
      "[INFO] Copying CSV ‚Üí OUTPUT\n",
      "       From: /kaggle/input/chewy-data/chewy_scraper_sample.csv\n",
      "       To:   /kaggle/working/excel_csv/chewy-data/chewy_scraper_sample.csv\n",
      "\n",
      "======================================================================\n",
      "BRIEF SUMMARY OF CREATED CSV FILES\n",
      "======================================================================\n",
      "\n",
      "File: /kaggle/working/excel_csv/pet-store-records-2020/pet_store_records_2020.csv\n",
      "  Shape: 879 rows √ó 11 columns\n",
      "  Columns: ['product_id', 'product_category', 'sales', 'price', 'VAP', 'vendor_id', 'country', 'pet_size', 'pet_type', 'rating', 're_buy']\n",
      "  Dtypes: {'product_id': 'int64', 'product_category': 'object', 'sales': 'int64', 'price': 'int64', 'VAP': 'int64', 'vendor_id': 'object', 'country': 'object', 'pet_size': 'object', 'pet_type': 'object', 'rating': 'int64', 're_buy': 'int64'}\n",
      "  Total missing values: 0\n",
      "  First 3 rows:\n",
      " product_id product_category  sales  price  VAP vendor_id country pet_size pet_type  rating  re_buy\n",
      "       5040        Equipment    123   7293    0   VC_1605 Vietnam    small     fish       7       1\n",
      "       4567             Toys     61   9304    1   VC_1132   India    small      cat      10       0\n",
      "       4237             Toys    218   8180    0    VC_802   India    small  hamster       6       0\n",
      "\n",
      "File: /kaggle/working/excel_csv/pet-food-customer-orders-online/pet_food_customer_orders.csv\n",
      "  Shape: 49042 rows √ó 36 columns\n",
      "  Columns: ['customer_id', 'pet_id', 'pet_order_number', 'wet_food_order_number', 'orders_since_first_wet_trays_order', 'pet_has_active_subscription', 'pet_food_tier', 'pet_signup_datetime', 'pet_allergen_list', 'pet_fav_flavour_list', 'pet_health_issue_list', 'neutered', 'gender', 'pet_breed_size', 'signup_promo', 'ate_wet_food_pre_tails', 'dry_food_brand_pre_tails', 'pet_life_stage_at_order', 'order_payment_date', 'kibble_kcal', 'wet_kcal', 'total_order_kcal', 'wet_trays', 'wet_food_discount_percent', 'wet_tray_size', 'premium_treat_packs', 'dental_treat_packs', 'wet_food_textures_in_order', 'total_web_sessions', 'total_web_sessions_since_last_order', 'total_minutes_on_website', 'total_minutes_on_website_since_last_order', 'total_wet_food_updates', 'total_wet_food_updates_since_last_order', 'last_customer_support_ticket_date', 'customer_support_ticket_category']\n",
      "  Dtypes: {'customer_id': 'uint64', 'pet_id': 'uint64', 'pet_order_number': 'int64', 'wet_food_order_number': 'float64', 'orders_since_first_wet_trays_order': 'float64', 'pet_has_active_subscription': 'bool', 'pet_food_tier': 'object', 'pet_signup_datetime': 'object', 'pet_allergen_list': 'object', 'pet_fav_flavour_list': 'object', 'pet_health_issue_list': 'object', 'neutered': 'bool', 'gender': 'object', 'pet_breed_size': 'object', 'signup_promo': 'object', 'ate_wet_food_pre_tails': 'bool', 'dry_food_brand_pre_tails': 'object', 'pet_life_stage_at_order': 'object', 'order_payment_date': 'object', 'kibble_kcal': 'float64', 'wet_kcal': 'float64', 'total_order_kcal': 'float64', 'wet_trays': 'int64', 'wet_food_discount_percent': 'float64', 'wet_tray_size': 'object', 'premium_treat_packs': 'int64', 'dental_treat_packs': 'int64', 'wet_food_textures_in_order': 'object', 'total_web_sessions': 'int64', 'total_web_sessions_since_last_order': 'int64', 'total_minutes_on_website': 'int64', 'total_minutes_on_website_since_last_order': 'int64', 'total_wet_food_updates': 'int64', 'total_wet_food_updates_since_last_order': 'int64', 'last_customer_support_ticket_date': 'object', 'customer_support_ticket_category': 'object'}\n",
      "  Total missing values: 355251\n",
      "  First 3 rows:\n",
      "         customer_id              pet_id  pet_order_number  wet_food_order_number  orders_since_first_wet_trays_order  pet_has_active_subscription pet_food_tier           pet_signup_datetime pet_allergen_list pet_fav_flavour_list pet_health_issue_list  neutered gender pet_breed_size   signup_promo  ate_wet_food_pre_tails dry_food_brand_pre_tails pet_life_stage_at_order            order_payment_date  kibble_kcal  wet_kcal  total_order_kcal  wet_trays  wet_food_discount_percent wet_tray_size  premium_treat_packs  dental_treat_packs wet_food_textures_in_order  total_web_sessions  total_web_sessions_since_last_order  total_minutes_on_website  total_minutes_on_website_since_last_order  total_wet_food_updates  total_wet_food_updates_since_last_order last_customer_support_ticket_date customer_support_ticket_category\n",
      "10574848487411271014 4466839344031767293                 2                    1.0                                 1.0                         True  superpremium 1970-01-01 00:00:01.552397819               NaN              Chicken     digestion, joints      True female          large Null & Default                    True                  Canagan                  mature 2019-04-11 00:00:00.000000000    36876.724   1234.65         38111.374         11                        0.0          150g                    0                   0           gravy jelly pate                   6                                    4                       101                                         32                       0                                        0         2019-03-16 09:10:12+00:00                        proactive\n",
      "10574848487411271014 4466839344031767293                 1                    NaN                                 NaN                         True  superpremium 1970-01-01 00:00:01.552397819               NaN              Chicken     digestion, joints      True female          large Null & Default                    True                  Canagan                  mature 2019-03-18 00:00:00.000000000    21419.305      0.00         21419.305          0                        NaN           NaN                    0                   0                        NaN                   2                                    1                        69                                          3                       0                                        0         2019-03-16 09:10:12+00:00                        proactive\n",
      "10574848487411271014 4466839344031767293                 8                    7.0                                 7.0                         True  superpremium 1970-01-01 00:00:01.552397819               NaN              Chicken     digestion, joints      True female          large Null & Default                    True                  Canagan                  mature 2019-10-27 00:00:00.000000000    18352.836   6624.00         24976.836         60                        0.0          150g                    0                   0           gravy jelly pate                  18                                    0                       184                                          0                       0                                        0         2019-10-26 06:10:13+00:00                          account\n",
      "\n",
      "File: /kaggle/working/excel_csv/e-commerce-pet-supplies-dataset/aliexpress_pet_supplies.csv\n",
      "  Shape: 1998 rows √ó 5 columns\n",
      "  Columns: ['title', 'averageStar', 'quantity', 'tradeAmount', 'wishedCount']\n",
      "  Dtypes: {'title': 'object', 'averageStar': 'float64', 'quantity': 'int64', 'tradeAmount': 'object', 'wishedCount': 'int64'}\n",
      "  Total missing values: 0\n",
      "  First 3 rows:\n",
      "                                                                                                                           title  averageStar  quantity tradeAmount  wishedCount\n",
      "                     Mesh Litter Spatula Poop Remover Pet Cleaning Supplies Large Litter Spatula Tofu Litter Litter Box Cat Poop          0.0      9993      5 sold            0\n",
      "Rechargeable Mini Pet Communication Small Recording Button Cats Dogs Eating Speaking Voice Speaker Buttons Talk Training Ringing          5.0      1986     28 sold           64\n",
      "                  Dog Cooling Bed Mat Summer Puppy Cushion Soft Non-slip Pet Sleeping Mats for Small Medium Dogs Pet Accessories          4.5       529     20 sold           38\n",
      "\n",
      "File: /kaggle/working/excel_csv/amazon-pet-supplies-data/amazon_pet_supplies_dataset_sample.csv\n",
      "  Shape: 343 rows √ó 15 columns\n",
      "  Columns: ['url', 'asin', 'title', 'price', 'currency', 'brand', 'images', 'overview', 'about_item', 'availability', 'description', 'specifications', 'breadcrumbs', 'uniq_id', 'scraped_at']\n",
      "  Dtypes: {'url': 'object', 'asin': 'object', 'title': 'object', 'price': 'object', 'currency': 'object', 'brand': 'object', 'images': 'object', 'overview': 'object', 'about_item': 'object', 'availability': 'object', 'description': 'object', 'specifications': 'object', 'breadcrumbs': 'object', 'uniq_id': 'object', 'scraped_at': 'object'}\n",
      "  Total missing values: 268\n",
      "  First 3 rows:\n",
      "                                url       asin                                                                                                                                                                                        title    price currency                    brand                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          images overview                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          about_item                        availability                                                                                                                                                                                  description                                                                                                                                                                                                                                                                                                specifications                                           breadcrumbs                              uniq_id scraped_at\n",
      "https://www.amazon.in/dp/B0796LTTT6 B0796LTTT6                                                                                                                                                                Retractable Cat Wand (Orange) 4,066.00      INR       Brand: Retractable                                                                                                                                                                                                                                                 https://m.media-amazon.com/images/I/51VTS7FvDRL._SS522_.jpg~https://m.media-amazon.com/images/I/31PHmP+t5sL._SS522_.jpg~https://m.media-amazon.com/images/I/31yG83hz2sL._SS522_.jpg~https://m.media-amazon.com/images/I/41qKmRmqTkL._SS522_.jpg       []                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 NaN Usually dispatched in 6 to 10 days.                                                                                                                                                                Retractable Cat Wand (Orange)                                                                                             [{'Manufacturer': '\\u200eRetractable'}, {'Country of Origin': '\\u200eUSA'}, {'Item part number': '\\u200e4334697300'}, {'ASIN': '\\u200eB0796LTTT6'}, {'Manufacturer': 'Retractable'}, {'Net Quantity': '1 count'}]             Pet Supplies | Cats | Toys | Feather Toys 380bad09-297f-59c4-8f58-0db9e98f9360 2022-07-25\n",
      "https://www.amazon.in/dp/B01LMH18YQ B01LMH18YQ                                                                                                                                             Avianweb Arm & Hand Perch (X-Large (1.5\" dowel))      NaN      NaN          Brand: Avianweb https://m.media-amazon.com/images/I/41tkMFbAxUL._SS522_.jpg~https://m.media-amazon.com/images/I/41AEufQAsML._SS522_.jpg~https://m.media-amazon.com/images/I/51TPYUpcCdL._SS522_.jpg~https://m.media-amazon.com/images/I/31075HjNJML._SS522_.jpg~https://m.media-amazon.com/images/I/31E+lxLuHLL._SS522_.jpg~https://m.media-amazon.com/images/I/41OX9vU37JL._SS522_.jpg~https://m.media-amazon.com/images/I/51vtp+cIHKL._SS522_.jpg~https://m.media-amazon.com/images/I/41sEmL5PsWL._SS522_.jpg       [] Protects against bites & scratches: Birds have sharp claws combined with a strong grip which can result in marks, scratches, and even painful bleeding puncture wounds on the bird owner's skin. Even the tamest bird is known to bite if startled or upset. | More Balance & Grip: Birds maintain a strong grip around a dowel but will easily lose balance when standing on a flat, moving surface (as on bird owner's arm or hand). The wooden perch itself sits elevated over the fabric to allow a bird to grip around it. | The Arm & Hand Perch adjusts easily to the bird owner's arm OR hand. Once it has been installed with the desired tension, the locking anchor keeps it in place, and the elastic cord will allow the owner to slip the arm and hand perch on and off easily, day after day, without having to make any additional adjustments. | Diameter of Perch: 1.5\" - suitable for average sized Macaws, Cockatoos and larger Amazon Parrots | NOTE: The preferences of the dowel diameter may differ, depending on a bird's past perching habits and physical challenges. It is best to choose a dowel size that is close to what a bird is using in its cage. The perch is removable and can be replaced with another size.                                 NaN                                                                                                                                                                                          NaN [{'Manufacturer': '\\u200eAvianweb LLC'}, {'Item model number': '\\u200eAV-XL-AHP'}, {'Product Dimensions': '\\u200e22.86 x 7.62 x 7.62 cm; 141.75 Grams'}, {'ASIN': '\\u200eB01LMH18YQ'}, {'Manufacturer': 'Avianweb LLC'}, {'Item Weight': '142 g'}, {'Item Dimensions LxWxH': '22.9 x 7.6 x 7.6 Centimeters'}] Pet Supplies | Birds | Birdcage Accessories | Perches 8d3a5b16-733e-5f8f-97b5-8c23a176d568 2022-07-23\n",
      "https://www.amazon.in/dp/B08JVLQS4P B08JVLQS4P Backyard Barnyard Chicken Swing Toy for Coop (Round Bar) Handmade in USA! Natural Safe Large Wood Perch Ladder for Poultry Run Rooster Hens Chicks Pet Parrots Pollo Stress Relief for Birds   199.00      INR Brand: Backyard Barnyard                                                             https://m.media-amazon.com/images/I/412neI904zL._SS522_.jpg~https://m.media-amazon.com/images/I/31uS36f3k8L._SS522_.jpg~https://m.media-amazon.com/images/I/31TpS-r9mnL._SS522_.jpg~https://m.media-amazon.com/images/I/51iJ11-PpZL._SS522_.jpg~https://m.media-amazon.com/images/I/41h8pe3YEBL._SS522_.jpg~https://m.media-amazon.com/images/I/31FUwO811ML._SS522_.jpg~https://m.media-amazon.com/images/I/31yRocucdGL._SS522_.jpg       []                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        üêî GREAT ADDITION TO ANY COOP OR PEN - Poultry swings are a must have for chicken owners | üêî NATURAL COMFORT FOR YOUR BIRDS -Perches allow birds to get off the ground and feel more secure | üêî WORKS FOR CHICKS TOO-Add to your list of brooder supplies to start training chicks early! | üêîPERFECT FOR ANY COOP- Our swings are adjustable up to 44 inches in height and built to last | üêîSOLID CONSTRUCTION - Our swings are hand crafted of solid wood and MADE IN USA!!!                                 NaN Backyard Barnyard Chicken Swing Toy for Coop (Round Bar) Handmade in USA! Natural Safe Large Wood Perch Ladder for Poultry Run Rooster Hens Chicks Pet Parrots Pollo Stress Relief for Birds                                                                                                  [{'Manufacturer': '\\u200eBackyard Barnyard'}, {'Package Dimensions': '\\u200e40.6 x 6.4 x 3.4 cm; 200 Grams'}, {'ASIN': '\\u200eB08JVLQS4P'}, {'Manufacturer': 'Backyard Barnyard'}, {'Item Weight': '200 g'}]                           Pet Supplies | Birds | Toys f8650333-e544-5609-bcea-89999d43b4c6 2022-07-24\n",
      "\n",
      "File: /kaggle/working/excel_csv/us-pet-food-supply-stores/US Pet Food  Supply Stores.csv\n",
      "  Shape: 875 rows √ó 52 columns\n",
      "  Columns: ['Business Name', 'City', 'State', 'ZIP', 'ZIP 4', 'Key Executive', 'Gender', 'Location Employee Size', 'Corporate Employee Size', 'Revenue / Yr', 'County Name', 'County Population', 'Metro Area', 'Latitude', 'Longitude', 'Main Line of Business', 'Location Type', 'Importer or Exporter', 'Manufacturer', 'Primary SIC', 'Primary SIC Description', 'NAICS', 'NAICS Description', 'Non-Profit', 'Number of PCs', 'Public / Private', 'Small Business', 'Square Footage', 'Website', 'Women Owned', 'Year Established', 'Business Credit Score', '2017 Revenue/Yr', '2016 Revenue/Yr', '2015 Revenue/Yr', '2016 % Sales Growth', '2015 % Sales Growth', '2017 Employees', '2016 Employees', '2015 Employees', '2016 % Employee Growth', '2015 % Employee Growth', 'Est. Accounting Annual Expense', 'Est. Advertising Annual Expense', 'Est. Business Insurance Annual Expense', 'Est. Legal Annual Expense', 'Est. Office Equipment Annual Expense', 'Est. Rent Annual Expense', 'Est. Technology Annual Expense', 'Est. Telecom Annual Expense', 'Est. Utilities Annual Expense', 'Franchise Type']\n",
      "  Dtypes: {'Business Name': 'object', 'City': 'object', 'State': 'object', 'ZIP': 'int64', 'ZIP 4': 'float64', 'Key Executive': 'object', 'Gender': 'object', 'Location Employee Size': 'object', 'Corporate Employee Size': 'object', 'Revenue / Yr': 'object', 'County Name': 'object', 'County Population': 'object', 'Metro Area': 'object', 'Latitude': 'float64', 'Longitude': 'float64', 'Main Line of Business': 'object', 'Location Type': 'object', 'Importer or Exporter': 'float64', 'Manufacturer': 'object', 'Primary SIC': 'int64', 'Primary SIC Description': 'object', 'NAICS': 'int64', 'NAICS Description': 'object', 'Non-Profit': 'object', 'Number of PCs': 'object', 'Public / Private': 'object', 'Small Business': 'object', 'Square Footage': 'object', 'Website': 'object', 'Women Owned': 'object', 'Year Established': 'float64', 'Business Credit Score': 'int64', '2017 Revenue/Yr': 'int64', '2016 Revenue/Yr': 'int64', '2015 Revenue/Yr': 'int64', '2016 % Sales Growth': 'float64', '2015 % Sales Growth': 'float64', '2017 Employees': 'int64', '2016 Employees': 'float64', '2015 Employees': 'float64', '2016 % Employee Growth': 'float64', '2015 % Employee Growth': 'float64', 'Est. Accounting Annual Expense': 'object', 'Est. Advertising Annual Expense': 'object', 'Est. Business Insurance Annual Expense': 'object', 'Est. Legal Annual Expense': 'object', 'Est. Office Equipment Annual Expense': 'object', 'Est. Rent Annual Expense': 'object', 'Est. Technology Annual Expense': 'object', 'Est. Telecom Annual Expense': 'object', 'Est. Utilities Annual Expense': 'object', 'Franchise Type': 'object'}\n",
      "  Total missing values: 2082\n",
      "  First 3 rows:\n",
      "Business Name       City State   ZIP  ZIP 4           Key Executive Gender Location Employee Size Corporate Employee Size     Revenue / Yr County Name County Population                     Metro Area  Latitude   Longitude Main Line of Business Location Type  Importer or Exporter Manufacturer  Primary SIC Primary SIC Description  NAICS                                               NAICS Description Non-Profit Number of PCs Public / Private Small Business Square Footage          Website Women Owned  Year Established  Business Credit Score  2017 Revenue/Yr  2016 Revenue/Yr  2015 Revenue/Yr  2016 % Sales Growth  2015 % Sales Growth  2017 Employees  2016 Employees  2015 Employees  2016 % Employee Growth  2015 % Employee Growth Est. Accounting Annual Expense Est. Advertising Annual Expense Est. Business Insurance Annual Expense Est. Legal Annual Expense Est. Office Equipment Annual Expense Est. Rent Annual Expense Est. Technology Annual Expense Est. Telecom Annual Expense Est. Utilities Annual Expense Franchise Type\n",
      "Food Lion LLC  Salisbury    NC 28147 9007.0 Chief Executive Officer   Male                     60                  61,209 $10,864,371,027        Rowan  25,000 to 49,999 Charlotte-Concord-Gastonia, NC 35.683334  -80.513657        Grocery Stores    Subsidiary                   NaN           No      5411001          Grocery Stores 445110      Supermarkets and Other Grocery (except Convenience) Stores         No   500 or more          Private             No 50,000 or more www.foodlion.com          No            1957.0                    100      10864371027                0                0                  0.0                  0.0              60            60.0            70.0                    0.00                  -14.29               $100,000 or more                $100,000 or more                       $100,000 or more          $100,000 or more                     $100,000 or more         $100,000 or more               $100,000 or more            $100,000 or more              $100,000 or more            NaN\n",
      "  Safeway Inc Pleasanton    CA 94588 3229.0               President   Male                     50                  46,073 $10,284,493,384      Alameda  50,000 to 99,999 San Francisco-Oakland-Berkeley 37.697386 -121.932882        Grocery Stores    Subsidiary                   NaN           No      5411001          Grocery Stores 445110      Supermarkets and Other Grocery (except Convenience) Stores         No   500 or more          Private             No 50,000 or more  www.safeway.com          No            1926.0                    100      10284493384                0                0                  0.0                  0.0              50             NaN             NaN                    0.00                    0.00               $100,000 or more                $100,000 or more                       $100,000 or more          $100,000 or more                     $100,000 or more         $100,000 or more               $100,000 or more            $100,000 or more              $100,000 or more            NaN\n",
      " PetSmart Inc    Phoenix    AZ 85027 4010.0 Chief Executive Officer   Male                      9                  53,000  $9,369,043,200     Maricopa   500,000 or more      Phoenix-Mesa-Chandler, AZ 33.663418 -112.115876         Retail Stores  Headquarters                   NaN           No      5999001           Retail Stores 453998 All Other Miscellaneous Store Retailers (except Tobacco Stores)         No   500 or more          Private             No 50,000 or more www.petsmart.com          No            1986.0                    100       9369043200       9369043200       9369043200                  0.0                  0.0               9         24000.0         24000.0                  -99.96                  -99.96               $100,000 or more                $100,000 or more                       $100,000 or more          $100,000 or more                     $100,000 or more         $100,000 or more               $100,000 or more            $100,000 or more              $100,000 or more            NaN\n",
      "\n",
      "File: /kaggle/working/excel_csv/sales-data-shop-pet/metrics_2023-01-01_to_2023-08-10_targeted_interest.csv\n",
      "  Shape: 2038 rows √ó 82 columns\n",
      "  Columns: [\"Centre d'int√©r√™t\", \"Statut du groupe d'annonces\", 'Nom de la campagne', \"Nom du groupe d'annonces\", \"Identifiant du groupe d'annonces\", 'Identifiant de la campagne', \"Emplacement du groupe d'annonces\", \"Type cr√©atif de campagne de groupe d'annonces\", \"Type de facturation du groupe d'annonces\", 'D√©penses', 'Objectif', 'R√©sultat', 'Type de r√©sultat', 'Co√ªt par r√©sultat', 'Co√ªt par type de r√©sultat', 'Impressions', 'CPM', \"Clics d'√âpingle\", 'CTR', 'Clics sortants', 'Conversions', \"Budget du groupe d'annonces\", \"Type de budget du groupe d'annonces\", \"Type de strat√©gie d'ench√®re de groupe d'annonces\", 'CPA cible du groupe d‚Äôannonces', \"Date/heure de d√©but du groupe d'annonces\", \"Date/heure de fin du groupe d'annonces\", \"Exp√©rience de groupes t√©moins du groupe d'annonces\", 'CPA total (paiement final)', 'ROAS total (paiement final)', 'Nombre total de conversions (paiement final)', 'Valeur totale de commande (paiement final)', 'Nombre total de conversions ‚Äì clics (paiement final)', 'Valeur totale de commande de clics (paiement final)', \"Nombre total de conversions d'engagements (paiement final)\", \"Valeur totale de commande d'engagements (paiement final)\", 'Nombre total de conversions de vues (paiement final)', 'Valeur totale de commande de vues (paiement final)', 'Total du CPA (Inscription)', 'Total du ROAS (Inscription)', 'Total des conversions (Inscription)', 'Valeur totale de commande (Inscription)', 'Total des conversions de clics (Inscription)', 'Valeur totale de commande de clics (Inscription)', \"Total des conversions d'engagement (Inscription)\", \"Valeur totale de commande d'engagement (Inscription)\", 'Total des conversions de vues (Inscription)', 'Valeur totale de commande de vues (Inscription)', 'Total du CPA (Lead)', 'Total du ROAS (Lead)', 'Total des conversions (Lead)', 'Valeur totale de commande (Lead)', 'Total des conversions de clics (Lead)', 'Valeur totale de commande de clics (Lead)', \"Total des conversions d'engagement (Lead)\", \"Valeur totale de commande d'engagement (Lead)\", 'Total des conversions de vues (Lead)', 'Valeur totale de commande de vues (Lead)', 'Total du CPA (Ajouter au panier)', 'Total du ROAS (Ajouter au panier)', 'Total des conversions (Ajouter au panier)', 'Valeur totale de la commande (Ajouter au panier)', 'Total des conversions de clics (Ajouter au panier)', 'Valeur totale de commande de clics (Ajouter au panier)', \"Total des conversions d'engagement (Ajouter au panier)\", \"Valeur totale de commande d'engagement (Ajouter au panier)\", 'Total des conversions de vues (Ajouter au panier)', 'Valeur totale des commandes de vues (Ajouter au panier)', \"Nombre brut d'impressions\", \"Nombre brut de clics d'√âpingle\", \"Nombre de visites via les balises de produit de l'√âpingle Id√©e pay√©es\", \"Nombre total de visites via les balises de produit de l'√âpingle Id√©e\", 'Taux de conversion total (Paiement final)', 'Taux de conversion total (Vue par cat√©gorie)', 'Taux de conversion total (Ajouter au panier)', 'Taux de conversion total (Inscription)', 'Taux de conversion total (Visite de page)', 'Taux de conversion total (Lead)', 'Taux de conversion total (Recherche site web)', 'Total des conversions (Voir la vid√©o)', 'Taux de conversion total (Inconnu)', 'Taux de conversion total (Personnalis√©)']\n",
      "  Dtypes: {\"Centre d'int√©r√™t\": 'object', \"Statut du groupe d'annonces\": 'object', 'Nom de la campagne': 'object', \"Nom du groupe d'annonces\": 'object', \"Identifiant du groupe d'annonces\": 'object', 'Identifiant de la campagne': 'object', \"Emplacement du groupe d'annonces\": 'int64', \"Type cr√©atif de campagne de groupe d'annonces\": 'float64', \"Type de facturation du groupe d'annonces\": 'object', 'D√©penses': 'object', 'Objectif': 'object', 'R√©sultat': 'object', 'Type de r√©sultat': 'object', 'Co√ªt par r√©sultat': 'object', 'Co√ªt par type de r√©sultat': 'object', 'Impressions': 'int64', 'CPM': 'object', \"Clics d'√âpingle\": 'int64', 'CTR': 'float64', 'Clics sortants': 'int64', 'Conversions': 'int64', \"Budget du groupe d'annonces\": 'object', \"Type de budget du groupe d'annonces\": 'object', \"Type de strat√©gie d'ench√®re de groupe d'annonces\": 'object', 'CPA cible du groupe d‚Äôannonces': 'int64', \"Date/heure de d√©but du groupe d'annonces\": 'float64', \"Date/heure de fin du groupe d'annonces\": 'object', \"Exp√©rience de groupes t√©moins du groupe d'annonces\": 'float64', 'CPA total (paiement final)': 'float64', 'ROAS total (paiement final)': 'float64', 'Nombre total de conversions (paiement final)': 'int64', 'Valeur totale de commande (paiement final)': 'float64', 'Nombre total de conversions ‚Äì clics (paiement final)': 'int64', 'Valeur totale de commande de clics (paiement final)': 'float64', \"Nombre total de conversions d'engagements (paiement final)\": 'int64', \"Valeur totale de commande d'engagements (paiement final)\": 'int64', 'Nombre total de conversions de vues (paiement final)': 'int64', 'Valeur totale de commande de vues (paiement final)': 'float64', 'Total du CPA (Inscription)': 'int64', 'Total du ROAS (Inscription)': 'float64', 'Total des conversions (Inscription)': 'int64', 'Valeur totale de commande (Inscription)': 'int64', 'Total des conversions de clics (Inscription)': 'int64', 'Valeur totale de commande de clics (Inscription)': 'int64', \"Total des conversions d'engagement (Inscription)\": 'int64', \"Valeur totale de commande d'engagement (Inscription)\": 'int64', 'Total des conversions de vues (Inscription)': 'int64', 'Valeur totale de commande de vues (Inscription)': 'int64', 'Total du CPA (Lead)': 'int64', 'Total du ROAS (Lead)': 'float64', 'Total des conversions (Lead)': 'int64', 'Valeur totale de commande (Lead)': 'int64', 'Total des conversions de clics (Lead)': 'int64', 'Valeur totale de commande de clics (Lead)': 'int64', \"Total des conversions d'engagement (Lead)\": 'int64', \"Valeur totale de commande d'engagement (Lead)\": 'int64', 'Total des conversions de vues (Lead)': 'int64', 'Valeur totale de commande de vues (Lead)': 'int64', 'Total du CPA (Ajouter au panier)': 'float64', 'Total du ROAS (Ajouter au panier)': 'float64', 'Total des conversions (Ajouter au panier)': 'int64', 'Valeur totale de la commande (Ajouter au panier)': 'float64', 'Total des conversions de clics (Ajouter au panier)': 'int64', 'Valeur totale de commande de clics (Ajouter au panier)': 'float64', \"Total des conversions d'engagement (Ajouter au panier)\": 'int64', \"Valeur totale de commande d'engagement (Ajouter au panier)\": 'int64', 'Total des conversions de vues (Ajouter au panier)': 'int64', 'Valeur totale des commandes de vues (Ajouter au panier)': 'float64', \"Nombre brut d'impressions\": 'int64', \"Nombre brut de clics d'√âpingle\": 'int64', \"Nombre de visites via les balises de produit de l'√âpingle Id√©e pay√©es\": 'int64', \"Nombre total de visites via les balises de produit de l'√âpingle Id√©e\": 'int64', 'Taux de conversion total (Paiement final)': 'int64', 'Taux de conversion total (Vue par cat√©gorie)': 'int64', 'Taux de conversion total (Ajouter au panier)': 'int64', 'Taux de conversion total (Inscription)': 'int64', 'Taux de conversion total (Visite de page)': 'int64', 'Taux de conversion total (Lead)': 'int64', 'Taux de conversion total (Recherche site web)': 'int64', 'Total des conversions (Voir la vid√©o)': 'int64', 'Taux de conversion total (Inconnu)': 'int64', 'Taux de conversion total (Personnalis√©)': 'int64'}\n",
      "  Total missing values: 6138\n",
      "  First 3 rows:\n",
      "   Centre d'int√©r√™t Statut du groupe d'annonces                  Nom de la campagne                 Nom du groupe d'annonces Identifiant du groupe d'annonces Identifiant de la campagne  Emplacement du groupe d'annonces  Type cr√©atif de campagne de groupe d'annonces Type de facturation du groupe d'annonces D√©penses       Objectif R√©sultat Type de r√©sultat Co√ªt par r√©sultat Co√ªt par type de r√©sultat  Impressions  CPM  Clics d'√âpingle      CTR  Clics sortants  Conversions Budget du groupe d'annonces Type de budget du groupe d'annonces Type de strat√©gie d'ench√®re de groupe d'annonces  CPA cible du groupe d‚Äôannonces  Date/heure de d√©but du groupe d'annonces Date/heure de fin du groupe d'annonces  Exp√©rience de groupes t√©moins du groupe d'annonces  CPA total (paiement final)  ROAS total (paiement final)  Nombre total de conversions (paiement final)  Valeur totale de commande (paiement final)  Nombre total de conversions ‚Äì clics (paiement final)  Valeur totale de commande de clics (paiement final)  Nombre total de conversions d'engagements (paiement final)  Valeur totale de commande d'engagements (paiement final)  Nombre total de conversions de vues (paiement final)  Valeur totale de commande de vues (paiement final)  Total du CPA (Inscription)  Total du ROAS (Inscription)  Total des conversions (Inscription)  Valeur totale de commande (Inscription)  Total des conversions de clics (Inscription)  Valeur totale de commande de clics (Inscription)  Total des conversions d'engagement (Inscription)  Valeur totale de commande d'engagement (Inscription)  Total des conversions de vues (Inscription)  Valeur totale de commande de vues (Inscription)  Total du CPA (Lead)  Total du ROAS (Lead)  Total des conversions (Lead)  Valeur totale de commande (Lead)  Total des conversions de clics (Lead)  Valeur totale de commande de clics (Lead)  Total des conversions d'engagement (Lead)  Valeur totale de commande d'engagement (Lead)  Total des conversions de vues (Lead)  Valeur totale de commande de vues (Lead)  Total du CPA (Ajouter au panier)  Total du ROAS (Ajouter au panier)  Total des conversions (Ajouter au panier)  Valeur totale de la commande (Ajouter au panier)  Total des conversions de clics (Ajouter au panier)  Valeur totale de commande de clics (Ajouter au panier)  Total des conversions d'engagement (Ajouter au panier)  Valeur totale de commande d'engagement (Ajouter au panier)  Total des conversions de vues (Ajouter au panier)  Valeur totale des commandes de vues (Ajouter au panier)  Nombre brut d'impressions  Nombre brut de clics d'√âpingle  Nombre de visites via les balises de produit de l'√âpingle Id√©e pay√©es  Nombre total de visites via les balises de produit de l'√âpingle Id√©e  Taux de conversion total (Paiement final)  Taux de conversion total (Vue par cat√©gorie)  Taux de conversion total (Ajouter au panier)  Taux de conversion total (Inscription)  Taux de conversion total (Visite de page)  Taux de conversion total (Lead)  Taux de conversion total (Recherche site web)  Total des conversions (Voir la vid√©o)  Taux de conversion total (Inconnu)  Taux de conversion total (Personnalis√©)\n",
      "Cuisine et Boissons                       Actif GingerDetox - Scaling - Conversions                      cuisine et boissons                  AG2680073087408              C626747005521                                 0                                            NaN                               Impression    25,17 WEB_CONVERSION       67          Actions              0,24                       CPC        10334 2,44              105 0.010161              18           67                           -                                   -                                      Automatique                               0                                       NaN                                      -                                                 NaN                         0.0                          0.0                                             0                                         0.0                                                     0                                                  0.0                                                           0                                                         0                                                     0                                                 0.0                           0                          0.0                                    0                                        0                                             0                                                 0                                                 0                                                     0                                            0                                                0                    0                   0.0                             0                                 0                                      0                                          0                                          0                                              0                                     0                                         0                          25.17166                           1.964511                                          1                                             49.45                                                   1                                                   49.45                                                       0                                                           0                                                  0                                                      0.0                      10503                             107                                                                      0                                                                     0                                          0                                             0                                             0                                       0                                          0                                0                                              0                                      0                                   0                                        0\n",
      "        (Automatic)                       Actif                PatchDetox - Scaling 2022-09-14 20:01 UTC¬†| Groupe d'annonces                  AG2680073175036              C626747061957                                 0                                            NaN                               Impression        0 WEB_CONVERSION        0          Actions                 0                       CPC           24    0                4 0.166667               1            0                           -                                   -                                      Automatique                               0                                       NaN                                      -                                                 NaN                         0.0                          NaN                                             0                                         0.0                                                     0                                                  0.0                                                           0                                                         0                                                     0                                                 0.0                           0                          NaN                                    0                                        0                                             0                                                 0                                                 0                                                     0                                            0                                                0                    0                   NaN                             0                                 0                                      0                                          0                                          0                                              0                                     0                                         0                           0.00000                                NaN                                          0                                              0.00                                                   0                                                    0.00                                                       0                                                           0                                                  0                                                      0.0                          0                               0                                                                      0                                                                     0                                          0                                             0                                             0                                       0                                          0                                0                                              0                                      0                                   0                                        0\n",
      "        (Automatic)                       Actif                      Promo Prodetox                 Promo Prodetox - Image 2                  AG2680074977065              C626748251676                                 0                                            NaN                               Impression     2,22 WEB_CONVERSION        7          Actions              0,25                       CPC         1070 2,08                9 0.008411               3            7                           -                                   -                                      Automatique                               0                                       NaN                                      -                                                 NaN                         0.0                          0.0                                             0                                         0.0                                                     0                                                  0.0                                                           0                                                         0                                                     0                                                 0.0                           0                          0.0                                    0                                        0                                             0                                                 0                                                 0                                                     0                                            0                                                0                    0                   0.0                             0                                 0                                      0                                          0                                          0                                              0                                     0                                         0                           0.00000                           0.000000                                          0                                              0.00                                                   0                                                    0.00                                                       0                                                           0                                                  0                                                      0.0                       1090                               9                                                                      0                                                                     0                                          0                                             0                                             0                                       0                                          0                                0                                              0                                      0                                   0                                        0\n",
      "\n",
      "File: /kaggle/working/excel_csv/chewy-data/chewy_scraper_sample.csv\n",
      "  Shape: 175 rows √ó 21 columns\n",
      "  Columns: ['url', 'name', 'sku', 'gtin12', 'breadcrumb', 'category_1', 'category_2', 'category_3', 'brand', 'Price', 'description', 'availability', 'images', 'average_rating', 'reviews_count', 'ingredients', 'calory_content', 'nutrition_analysis', 'feeding_instructions', 'uniq_id', 'scraped_at']\n",
      "  Dtypes: {'url': 'object', 'name': 'object', 'sku': 'int64', 'gtin12': 'float64', 'breadcrumb': 'object', 'category_1': 'float64', 'category_2': 'float64', 'category_3': 'float64', 'brand': 'object', 'Price': 'object', 'description': 'object', 'availability': 'object', 'images': 'object', 'average_rating': 'float64', 'reviews_count': 'float64', 'ingredients': 'object', 'calory_content': 'object', 'nutrition_analysis': 'object', 'feeding_instructions': 'object', 'uniq_id': 'object', 'scraped_at': 'object'}\n",
      "  Total missing values: 1189\n",
      "  First 3 rows:\n",
      "                                                                 url                                                                                             name    sku       gtin12                                                    breadcrumb  category_1  category_2  category_3                brand  Price                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           description availability                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   images  average_rating  reviews_count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ingredients calory_content                                                                                                                                                                                                                                                              nutrition_analysis feeding_instructions                              uniq_id          scraped_at\n",
      " https://www.chewy.com/formula-champions-game-plan-starter/dp/232829   Formula of Champions Game Plan Starter-Developer 18% Medicated Show Goat Feed With Decoquinate 206228 8.463360e+11                                Farm Animal>Goat>Feed & Treats         NaN         NaN         NaN Formula of Champions $38.49                                                                                                                                                                                                            Formula of Champions Game Plan 18% Starter Developer Goat Feed encourages weight gain and health in young goats. Designed to be fed with forage, this feed includes quality ingredients that encourage bloom. The feed is medicated to help prevent coccidiosis, and includes ammonium chloride to help prevent urinary calculi or water belly. Chelated minerals support cell absorption, immunity, haircoat and skin condition, preparing your goat for the show ring‚Äîno kidding around!      InStock                                                                                                                                                                                                                                                                                                                  ['https://image.chewy.com/is/image/catalog/206228_MAIN._AC_SS500_V1675118679_.jpg', 'https://image.chewy.com/is/image/catalog/206228_PT1._AC_SS500_V1675278810_.jpg', 'https://image.chewy.com/is/image/catalog/206228_PT2._AC_SS500_V1675176302_.jpg']          1.0000            1.0 Dehydrated Alfalfa Meal, Ground Corn, Soybean Hulls, Soybean Meal, Wheat Middlings, Corn Distillers Dried Grains with Solubles, Extruded Soybean Meal, Cane Molasses, Starch, Salt, Canola Meal, Monocalcium Phosphate, Calcium Carbonate, Active Dry Yeast, Yeast Extract, Soybean Oil, Dried Whey, Ammonium Chloride,  Potassium Sulfate, Magnesium Sulfate, Magnesium Oxide, Potassium Chloride, Vitamin A Supplement, Vitamin E Supplement, Vitamin D-3 Supplement, Biotin, Folic Acid, Vitamin B-12 Supplement, Calcium Pantothenate, Niacin, Thiamine Mononitrate, Menadione Dimethylpyrimidinol Bisulfite (Source of Vitamin K Activity), Riboflavin, Pyridoxine Hydrochloride, Zinc Amino Acid Complex, Manganese Amino Acid Complex, Copper Amino Acid Complex, Cobalt Glucoheptonate, Zinc Sulfate, Ferrous Sulfate, Manganese Sulfate, Copper Sulfate, Ethylene Diamine Dihydriodide, Cobalt Sulfate, Selenium Yeast, Sodium Selenite, DL-Methionine Hydroxy Analog Isopropyl Ester, L-Lysine, Dried Aspergillus oryzae Fermentation Product, Natural and Artificial Flavoring.            NaN Crude Protein: 18.0% min | Crude Fat: 4.00% min | Crude Fiber: 15.00% max | Calcium: 0.75% min | Calcium: 1.25% max | Phosphorus: 0.40% min | Salt: 0.50% min | Salt: 0.75% max | Selenium: 0.60 ppm min | Copper: 30 ppm min | Copper: 50 ppm max | Vitamin A: 8,000 IU/lb min                  NaN 1a03bc9e-2e28-5f0a-86f3-97033ded8c23 03/05/2023 21:37:22\n",
      "    https://www.chewy.com/quick-tag-star-wars-mandalorians/dp/312688 Quick-Tag Star Wars The Mandalorian's The Child Baby Yoda Military Personalized Dog & Cat ID Tag 286322 7.365110e+11        Cat>Leashes, Collars & Harnesses>ID Tags & Accessories         NaN         NaN         NaN            Quick-Tag $19.99                                                                                                                                    If your pet is the Grogu to your Mando, the Quick-Tag Star Wars The Mandalorian's The Child Baby Yoda Military Personalized Dog & Cat ID Tag is a must! This super sturdy tag is made out of brass and painted with a fun design. It‚Äôs the paw-fect size to hold all of your pal‚Äôs important information like medical conditions, addresses, and phone numbers. To top it off, the customizable side features permanent, clear laser engraving, helping it endure tons of wear and tear. For a collar charm that‚Äôs as cute as your BFF, this tag is your best bet!      InStock                                                                                                                                                                                                                                ['https://image.chewy.com/is/image/catalog/286322_MAIN._AC_SS500_V1619217117_.jpg', 'https://image.chewy.com/is/image/catalog/286322_PT1._AC_SS500_V1619217138_.jpg', 'https://image.chewy.com/is/image/catalog/286322_PT2._AC_SS500_V1619217151_.jpg', 'https://image.chewy.com/is/image/catalog/286322_PT3._AC_SS500_V1619217163_.jpg']          3.6667            3.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        NaN            NaN                                                                                                                                                                                                                                                                             NaN                  NaN 26f3e20c-3808-5700-b99d-c99b69c809be 03/05/2023 21:37:22\n",
      "https://www.chewy.com/pet-md-deodorizing-sweet-pea-vanilla/dp/654094                         Pet MD Deodorizing Sweet Pea & Vanilla Cat & Dog Body Spray, 8 oz bottle 654102 8.500128e+11 Cat>Grooming>Waterless Grooming>Deodorizing Sprays & Colognes         NaN         NaN         NaN               Pet MD $12.99 Help tame your fur baby‚Äôs coat and control any odors with Pet MD Deodorizing Sweet Pea & Vanilla Cat & Dog Body Spray! Made in the USA, this water-based, deodorizing spray is infused with all-natural sweet pea and vanilla fragrances‚Äîit is gentle enough to use on pets with sensitive skin, including cats, dogs, horses, and pocket pets over 12 weeks old. It is designed to eliminate odors for long periods of time, including those in hard-to-reach areas like skin folds and undercoats. It naturally reduces static as well, so it is helpful for taming wild coats. Its refreshing scent, static-reduction, and mild cleansing action helps minimize expensive grooming visits as well!      InStock ['https://image.chewy.com/is/image/catalog/654102_MAIN._AC_SS500_V1665666978_.jpg', 'https://image.chewy.com/is/image/catalog/654102_PT1._AC_SS500_V1665780877_.jpg', 'https://image.chewy.com/is/image/catalog/654102_PT2._AC_SS500_V1665669565_.jpg', 'https://image.chewy.com/is/image/catalog/654102_PT3._AC_SS500_V1665781546_.jpg', 'https://image.chewy.com/is/image/catalog/654102_PT4._AC_SS500_V1665781461_.jpg', 'https://image.chewy.com/is/image/catalog/654102_PT5._AC_SS500_V1665670218_.jpg', 'https://chewy.wistia.com/embed/medias/0qh6b3f09r/swatch']          1.0000            1.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Water, Polysorbate 20, PEG-40 Hydrogenated Castor Oil, Panthenol, Aloe Barbadensis (Aloe Vera) Leaf Juice, Fragrance, Methylisothiazolinone.            NaN                                                                                                                                                                                                                                                                             NaN                  NaN 3dc093b4-256f-5348-b05d-225e4da26cb7 03/05/2023 21:37:22\n",
      "\n",
      "[DIR TREE] /kaggle/working/excel_csv\n",
      "excel_csv/\n",
      "    amazon-pet-supplies-data/\n",
      "        amazon_pet_supplies_dataset_sample.csv\n",
      "    chewy-data/\n",
      "        chewy_scraper_sample.csv\n",
      "    e-commerce-pet-supplies-dataset/\n",
      "        aliexpress_pet_supplies.csv\n",
      "    pet-food-customer-orders-online/\n",
      "        pet_food_customer_orders.csv\n",
      "    pet-store-records-2020/\n",
      "        pet_store_records_2020.csv\n",
      "    sales-data-shop-pet/\n",
      "        metrics_2023-01-01_to_2023-08-10_targeted_interest.csv\n",
      "    us-pet-food-supply-stores/\n",
      "        US Pet Food  Supply Stores.csv\n",
      "\n",
      "[DONE] All Excel and CSV files copied/converted to OUTPUT with summaries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "INPUT_ROOT = \"/kaggle/input\"\n",
    "OUTPUT_ROOT = \"/kaggle/working/excel_csv\"\n",
    "EXCEL_EXTS = {\".xls\", \".xlsx\", \".xlsm\"}\n",
    "CSV_EXTS = {\".csv\"}\n",
    "\n",
    "os.makedirs(OUTPUT_ROOT, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------\n",
    "# 1) Helper: Print folder tree\n",
    "# ---------------------------------------\n",
    "def print_tree(root_path):\n",
    "    \"\"\"\n",
    "    Print a simple 'tree' of the given root directory.\n",
    "    \"\"\"\n",
    "    print(f\"\\n[DIR TREE] {root_path}\")\n",
    "    if not os.path.exists(root_path):\n",
    "        print(\"  (path does not exist)\")\n",
    "        return\n",
    "\n",
    "    def _walk(path, prefix=\"\"):\n",
    "        name = os.path.basename(path.rstrip(os.sep))\n",
    "        if not name:  # root like \"/\"\n",
    "            name = path\n",
    "        print(prefix + name + \"/\")\n",
    "        try:\n",
    "            entries = sorted(os.listdir(path))\n",
    "        except PermissionError:\n",
    "            print(prefix + \"    [Permission denied]\")\n",
    "            return\n",
    "\n",
    "        for entry in entries:\n",
    "            full = os.path.join(path, entry)\n",
    "            if os.path.isdir(full):\n",
    "                _walk(full, prefix + \"    \")\n",
    "            else:\n",
    "                print(prefix + \"    \" + entry)\n",
    "\n",
    "    _walk(root_path)\n",
    "\n",
    "# ---------------------------------------\n",
    "# 2) Show the INPUT folder tree\n",
    "# ---------------------------------------\n",
    "print_tree(INPUT_ROOT)\n",
    "\n",
    "# ---------------------------------------\n",
    "# 3) Walk /kaggle/input and process Excel + CSV\n",
    "#    - Excel: convert ‚Üí CSV in OUTPUT_ROOT\n",
    "#    - CSV:  copy (read & write) ‚Üí OUTPUT_ROOT\n",
    "# ---------------------------------------\n",
    "summaries = []\n",
    "\n",
    "for dirpath, _, filenames in os.walk(INPUT_ROOT):\n",
    "    for fname in filenames:\n",
    "        ext = os.path.splitext(fname)[1].lower()\n",
    "        if ext not in EXCEL_EXTS and ext not in CSV_EXTS:\n",
    "            continue  # skip non-tabular files\n",
    "\n",
    "        src_path = os.path.join(dirpath, fname)\n",
    "\n",
    "        # Keep the same relative folder structure under OUTPUT_ROOT\n",
    "        rel_dir = os.path.relpath(dirpath, INPUT_ROOT)\n",
    "        out_dir = os.path.join(OUTPUT_ROOT, rel_dir)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        base = os.path.splitext(fname)[0]\n",
    "        out_csv_path = os.path.join(out_dir, base + \".csv\")\n",
    "\n",
    "        # Decide how to read\n",
    "        if ext in EXCEL_EXTS:\n",
    "            print(f\"\\n[INFO] Converting Excel ‚Üí CSV\")\n",
    "            print(f\"       From: {src_path}\")\n",
    "            print(f\"       To:   {out_csv_path}\")\n",
    "            df = pd.read_excel(src_path)\n",
    "        else:  # CSV_EXTS\n",
    "            print(f\"\\n[INFO] Copying CSV ‚Üí OUTPUT\")\n",
    "            print(f\"       From: {src_path}\")\n",
    "            print(f\"       To:   {out_csv_path}\")\n",
    "            df = pd.read_csv(src_path)\n",
    "\n",
    "        # Write CSV to output directory\n",
    "        df.to_csv(out_csv_path, index=False)\n",
    "\n",
    "        # Store summary\n",
    "        summary = {\n",
    "            \"csv_path\": out_csv_path,\n",
    "            \"n_rows\": df.shape[0],\n",
    "            \"n_cols\": df.shape[1],\n",
    "            \"columns\": list(df.columns),\n",
    "            \"dtypes\": df.dtypes.astype(str).to_dict(),\n",
    "            \"missing_total\": int(df.isna().sum().sum()),\n",
    "            \"preview\": df.head(3).to_string(index=False)\n",
    "        }\n",
    "        summaries.append(summary)\n",
    "\n",
    "# ---------------------------------------\n",
    "# 4) Print summary for each CSV\n",
    "# ---------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BRIEF SUMMARY OF CREATED CSV FILES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if not summaries:\n",
    "    print(\"No Excel or CSV files were processed under /kaggle/input.\")\n",
    "else:\n",
    "    for s in summaries:\n",
    "        print(f\"\\nFile: {s['csv_path']}\")\n",
    "        print(f\"  Shape: {s['n_rows']} rows √ó {s['n_cols']} columns\")\n",
    "        print(f\"  Columns: {s['columns']}\")\n",
    "        print(f\"  Dtypes: {s['dtypes']}\")\n",
    "        print(f\"  Total missing values: {s['missing_total']}\")\n",
    "        print(\"  First 3 rows:\")\n",
    "        print(s[\"preview\"])\n",
    "\n",
    "# ---------------------------------------\n",
    "# 5) Show the OUTPUT folder tree\n",
    "# ---------------------------------------\n",
    "print_tree(OUTPUT_ROOT)\n",
    "\n",
    "print(\"\\n[DONE] All Excel and CSV files copied/converted to OUTPUT with summaries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:47:43.746365Z",
     "iopub.status.busy": "2025-11-14T14:47:43.745930Z",
     "iopub.status.idle": "2025-11-14T14:47:50.042141Z",
     "shell.execute_reply": "2025-11-14T14:47:50.040811Z",
     "shell.execute_reply.started": "2025-11-14T14:47:43.746332Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting implicit\n",
      "  Downloading implicit-0.7.2-cp311-cp311-manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from implicit) (1.26.4)\n",
      "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.11/dist-packages (from implicit) (1.15.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from implicit) (4.67.1)\n",
      "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from implicit) (3.6.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->implicit) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->implicit) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->implicit) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->implicit) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->implicit) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.0->implicit) (2.4.1)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.0->implicit) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.0->implicit) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.0->implicit) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.0->implicit) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.0->implicit) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.0->implicit) (2024.2.0)\n",
      "Downloading implicit-0.7.2-cp311-cp311-manylinux2014_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: implicit\n",
      "Successfully installed implicit-0.7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "    pip install implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:47:50.045617Z",
     "iopub.status.busy": "2025-11-14T14:47:50.045295Z",
     "iopub.status.idle": "2025-11-14T14:47:59.897405Z",
     "shell.execute_reply": "2025-11-14T14:47:59.896461Z",
     "shell.execute_reply.started": "2025-11-14T14:47:50.045585Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSVs...\n",
      "tails    ‚Üí  49042 rows √ó  36 cols\n",
      "store    ‚Üí    879 rows √ó  11 cols\n",
      "chewy    ‚Üí    175 rows √ó  21 cols\n",
      "amz      ‚Üí    343 rows √ó  15 cols\n",
      "ali      ‚Üí   1998 rows √ó   5 cols\n",
      "usst     ‚Üí    875 rows √ó  52 cols\n",
      "metrics  ‚Üí   2038 rows √ó  82 cols\n",
      "\n",
      "=== BASIC EDA ===\n",
      "\n",
      "[TAILS] pet_food_customer_orders overview\n",
      "            customer_id               pet_id  pet_order_number pet_food_tier  \\\n",
      "0  10574848487411271014  4466839344031767293                 2  superpremium   \n",
      "1  10574848487411271014  4466839344031767293                 1  superpremium   \n",
      "2  10574848487411271014  4466839344031767293                 8  superpremium   \n",
      "3  10574848487411271014  4466839344031767293                 4  superpremium   \n",
      "4  10574848487411271014  4466839344031767293                 9  superpremium   \n",
      "\n",
      "  wet_tray_size  wet_trays  \n",
      "0          150g         11  \n",
      "1           NaN          0  \n",
      "2          150g         60  \n",
      "3          150g         26  \n",
      "4          150g         60  \n",
      "\n",
      "[TAILS] pet_food_tier value counts:\n",
      "pet_food_tier\n",
      "superpremium    28531\n",
      "mid             11518\n",
      "premium          8993\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[TAILS] wet_tray_size value counts:\n",
      "wet_tray_size\n",
      "NaN     36254\n",
      "150g     7635\n",
      "300g     5152\n",
      "Both        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[STORE] pet_store_records_2020 overview\n",
      "   product_id product_category vendor_id  country pet_type pet_size  rating  \\\n",
      "0        5040        Equipment   VC_1605  Vietnam     fish    small       7   \n",
      "1        4567             Toys   VC_1132    India      cat    small      10   \n",
      "2        4237             Toys    VC_802    India  hamster    small       6   \n",
      "3        4364            Snack    VC_929    India      dog    large       1   \n",
      "4        4184      Supplements    VC_749    India      dog    large      10   \n",
      "\n",
      "   re_buy  \n",
      "0       1  \n",
      "1       0  \n",
      "2       0  \n",
      "3       1  \n",
      "4       0  \n",
      "\n",
      "[STORE] product_category value counts:\n",
      "product_category\n",
      "Equipment      141\n",
      "Toys           141\n",
      "Snack          141\n",
      "Medicine        76\n",
      "Supplements     75\n",
      "Food            75\n",
      "Bedding         46\n",
      "Housing         46\n",
      "Clothes         46\n",
      "Accessory       46\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[STORE] pet_type value counts:\n",
      "pet_type\n",
      "cat        347\n",
      "dog        347\n",
      "fish        70\n",
      "bird        69\n",
      "hamster     23\n",
      "rabbit      23\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[CHEWY] sample:\n",
      "                                                name                 brand  \\\n",
      "0  Formula of Champions Game Plan Starter-Develop...  Formula of Champions   \n",
      "1  Quick-Tag Star Wars The Mandalorian's The Chil...             Quick-Tag   \n",
      "2  Pet MD Deodorizing Sweet Pea & Vanilla Cat & D...                Pet MD   \n",
      "\n",
      "                                          breadcrumb   Price  average_rating  \n",
      "0                     Farm Animal>Goat>Feed & Treats  $38.49          1.0000  \n",
      "1  Cat>Leashes, Collars & Harnesses>ID Tags & Acc...  $19.99          3.6667  \n",
      "2  Cat>Grooming>Waterless Grooming>Deodorizing Sp...  $12.99          1.0000  \n",
      "\n",
      "[AMAZON] sample:\n",
      "                                               title  \\\n",
      "0                      Retractable Cat Wand (Orange)   \n",
      "1   Avianweb Arm & Hand Perch (X-Large (1.5\" dowel))   \n",
      "2  Backyard Barnyard Chicken Swing Toy for Coop (...   \n",
      "\n",
      "                      brand     price currency  \\\n",
      "0        Brand: Retractable  4,066.00      INR   \n",
      "1           Brand: Avianweb       NaN      NaN   \n",
      "2  Brand: Backyard Barnyard    199.00      INR   \n",
      "\n",
      "                                         breadcrumbs  \n",
      "0          Pet Supplies | Cats | Toys | Feather Toys  \n",
      "1  Pet Supplies | Birds | Birdcage Accessories | ...  \n",
      "2                        Pet Supplies | Birds | Toys  \n",
      "\n",
      "[ALIEXPRESS] sample:\n",
      "                                               title  averageStar  quantity  \\\n",
      "0  Mesh Litter Spatula Poop Remover Pet Cleaning ...          0.0      9993   \n",
      "1  Rechargeable Mini Pet Communication Small Reco...          5.0      1986   \n",
      "2  Dog Cooling Bed Mat Summer Puppy Cushion Soft ...          4.5       529   \n",
      "\n",
      "  tradeAmount  wishedCount  \n",
      "0      5 sold            0  \n",
      "1     28 sold           64  \n",
      "2     20 sold           38  \n",
      "\n",
      "[US Stores] sample:\n",
      "   Business Name        City State Main Line of Business\n",
      "0  Food Lion LLC   Salisbury    NC        Grocery Stores\n",
      "1    Safeway Inc  Pleasanton    CA        Grocery Stores\n",
      "2   PetSmart Inc     Phoenix    AZ         Retail Stores\n",
      "\n",
      "[Metrics] columns:\n",
      "Index(['Centre d'int√©r√™t', 'Statut du groupe d'annonces', 'Nom de la campagne',\n",
      "       'Nom du groupe d'annonces', 'Identifiant du groupe d'annonces',\n",
      "       'Identifiant de la campagne', 'Emplacement du groupe d'annonces',\n",
      "       'Type cr√©atif de campagne de groupe d'annonces',\n",
      "       'Type de facturation du groupe d'annonces', 'D√©penses', 'Objectif',\n",
      "       'R√©sultat', 'Type de r√©sultat', 'Co√ªt par r√©sultat',\n",
      "       'Co√ªt par type de r√©sultat'],\n",
      "      dtype='object')\n",
      "\n",
      "[Metrics] sample:\n",
      "      Centre d'int√©r√™t Statut du groupe d'annonces  \\\n",
      "0  Cuisine et Boissons                       Actif   \n",
      "1          (Automatic)                       Actif   \n",
      "2          (Automatic)                       Actif   \n",
      "\n",
      "                    Nom de la campagne  \\\n",
      "0  GingerDetox - Scaling - Conversions   \n",
      "1                 PatchDetox - Scaling   \n",
      "2                       Promo Prodetox   \n",
      "\n",
      "                   Nom du groupe d'annonces Identifiant du groupe d'annonces  \\\n",
      "0                       cuisine et boissons                  AG2680073087408   \n",
      "1  2022-09-14 20:01 UTC¬†| Groupe d'annonces                  AG2680073175036   \n",
      "2                  Promo Prodetox - Image 2                  AG2680074977065   \n",
      "\n",
      "  Identifiant de la campagne  Emplacement du groupe d'annonces  \\\n",
      "0              C626747005521                                 0   \n",
      "1              C626747061957                                 0   \n",
      "2              C626748251676                                 0   \n",
      "\n",
      "   Type cr√©atif de campagne de groupe d'annonces  \\\n",
      "0                                            NaN   \n",
      "1                                            NaN   \n",
      "2                                            NaN   \n",
      "\n",
      "  Type de facturation du groupe d'annonces D√©penses  ...  \\\n",
      "0                               Impression    25,17  ...   \n",
      "1                               Impression        0  ...   \n",
      "2                               Impression     2,22  ...   \n",
      "\n",
      "  Taux de conversion total (Paiement final)  \\\n",
      "0                                         0   \n",
      "1                                         0   \n",
      "2                                         0   \n",
      "\n",
      "  Taux de conversion total (Vue par cat√©gorie)  \\\n",
      "0                                            0   \n",
      "1                                            0   \n",
      "2                                            0   \n",
      "\n",
      "  Taux de conversion total (Ajouter au panier)  \\\n",
      "0                                            0   \n",
      "1                                            0   \n",
      "2                                            0   \n",
      "\n",
      "  Taux de conversion total (Inscription)  \\\n",
      "0                                      0   \n",
      "1                                      0   \n",
      "2                                      0   \n",
      "\n",
      "  Taux de conversion total (Visite de page)  Taux de conversion total (Lead)  \\\n",
      "0                                         0                                0   \n",
      "1                                         0                                0   \n",
      "2                                         0                                0   \n",
      "\n",
      "  Taux de conversion total (Recherche site web)  \\\n",
      "0                                             0   \n",
      "1                                             0   \n",
      "2                                             0   \n",
      "\n",
      "   Total des conversions (Voir la vid√©o)  Taux de conversion total (Inconnu)  \\\n",
      "0                                      0                                   0   \n",
      "1                                      0                                   0   \n",
      "2                                      0                                   0   \n",
      "\n",
      "   Taux de conversion total (Personnalis√©)  \n",
      "0                                        0  \n",
      "1                                        0  \n",
      "2                                        0  \n",
      "\n",
      "[3 rows x 82 columns]\n",
      "\n",
      "=== BUILD INTERACTIONS ===\n",
      "Interactions from Tails: (15543, 3)\n",
      "Interactions from Store: (879, 3)\n",
      "Total interactions (raw): (16422, 3)\n",
      "Total interactions (filtered): (7814, 3)\n",
      "\n",
      "Number of distinct users: 3439\n",
      "Number of distinct items: 159\n",
      "Top 10 most popular items:\n",
      " item_key\n",
      "tails_superpremium|150g|mature|small     11826.5\n",
      "tails_superpremium|300g|mature|small      8307.8\n",
      "tails_superpremium|300g|mature|medium     7422.3\n",
      "tails_superpremium|300g|mature|large      7069.9\n",
      "tails_superpremium|150g|mature|medium     6713.7\n",
      "tails_superpremium|150g|mature|toy        6456.3\n",
      "tails_premium|150g|mature|small           4483.6\n",
      "tails_mid|150g|mature|small               4477.8\n",
      "tails_premium|300g|mature|medium          3652.3\n",
      "tails_superpremium|150g|senior|small      3475.6\n",
      "Name: weight, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoded users: 3439, items: 159\n",
      "Train interactions: (4375, 5)\n",
      "Test interactions: (3439, 5)\n",
      "Sparse shapes ‚Äî train: (3439, 159) test: (3439, 159)\n",
      "\n",
      "Unified item catalog size: (3557, 8)\n",
      "                               item_key source      category  size pet_type  \\\n",
      "0  tails_superpremium|150g|mature|large  tails  superpremium  150g      NaN   \n",
      "1  tails_superpremium|none|mature|large  tails  superpremium  none      NaN   \n",
      "2      tails_premium|none|mature|medium  tails       premium  none      NaN   \n",
      "3    tails_mid|none|half_maturity|small  tails           mid  none      NaN   \n",
      "4          tails_mid|none|weaning|small  tails           mid  none      NaN   \n",
      "\n",
      "  name brand  item_id  \n",
      "0  NaN   NaN      109  \n",
      "1  NaN   NaN      145  \n",
      "2  NaN   NaN       90  \n",
      "3  NaN   NaN       36  \n",
      "4  NaN   NaN       51  \n",
      "Core items: 1041 External items: 2516\n",
      "Similarity matrix shape: (2516, 1041)\n",
      "Number of core items with real users: 159\n",
      "Synthetic interactions generated: 95\n",
      "Original interactions: (7814, 5)\n",
      "Augmented interactions: (7909, 3)\n",
      "Augmented interactions after filtering: (7909, 3)\n",
      "\n",
      "Encoded users (augmented): 3439, items: 165\n",
      "Train interactions: (4470, 5)\n",
      "Test interactions: (3439, 5)\n",
      "Sparse shapes ‚Äî train: (3439, 165) test: (3439, 165)\n",
      "\n",
      "=== MODEL 1: Popularity baseline ===\n",
      "Popularity ‚Üí Recall@10 = 0.1215, MAP@10 = 0.0506\n",
      "\n",
      "=== MODEL 2: Item-kNN (cosine) ===\n",
      "Item-kNN   ‚Üí Recall@10 = 0.6930, MAP@10 = 0.3654\n",
      "\n",
      "=== MODEL 3: ALS (implicit) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/implicit/cpu/als.py:95: RuntimeWarning: Intel MKL BLAS is configured to use 2 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'MKL_NUM_THREADS=1' or by callng 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having MKL use a threadpool can lead to severe performance issues\n",
      "  check_blas_config()\n",
      "/usr/local/lib/python3.11/dist-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 4 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09251281a8ed44f39303ad0249bb62a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS training done.\n",
      "ALS        ‚Üí Recall@10 = 0.3605, MAP@10 = 0.2025\n",
      "\n",
      "=== MODEL COMPARISON ===\n",
      "        model  Recall@10    MAP@10\n",
      "0  Popularity     0.1215  0.050592\n",
      "1    Item-kNN     0.6930  0.365411\n",
      "2         ALS     0.3605  0.202511\n",
      "\n",
      "=== EXAMPLE RECOMMENDATIONS (ALS) ===\n",
      "Recommendations for customer_id=10574848487411271014:\n",
      "                                      item_key source      category  size\n",
      "0         tails_superpremium|none|senior|large  tails  superpremium  none\n",
      "1  tails_superpremium|150g|half_maturity|large  tails  superpremium  150g\n",
      "2                 tails_mid|150g|senior|medium  tails           mid  150g\n",
      "3       tails_premium|none|half_maturity|large  tails       premium  none\n",
      "4  tails_superpremium|150g|half_maturity|giant  tails  superpremium  150g\n",
      "5                  tails_mid|300g|mature|large  tails           mid  300g\n",
      "6         tails_superpremium|150g|senior|large  tails  superpremium  150g\n",
      "7                  tails_mid|300g|mature|small  tails           mid  300g\n",
      "8      tails_premium|150g|half_maturity|medium  tails       premium  150g\n",
      "9                 tails_mid|150g|weaning|large  tails           mid  150g\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Pet-Shop Recommender: Preprocessing, EDA, Multi-Model Compare\n",
    "# ============================================================\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# If needed on Kaggle:\n",
    "# !pip install implicit\n",
    "\n",
    "import implicit\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0) LOAD ALL DATA\n",
    "# ------------------------------------------------------------\n",
    "BASE = \"/kaggle/working/excel_csv\"\n",
    "\n",
    "paths = {\n",
    "    \"tails\":   os.path.join(BASE, \"pet-food-customer-orders-online\", \"pet_food_customer_orders.csv\"),\n",
    "    \"store\":   os.path.join(BASE, \"pet-store-records-2020\", \"pet_store_records_2020.csv\"),\n",
    "    \"chewy\":   os.path.join(BASE, \"chewy-data\", \"chewy_scraper_sample.csv\"),\n",
    "    \"amz\":     os.path.join(BASE, \"amazon-pet-supplies-data\", \"amazon_pet_supplies_dataset_sample.csv\"),\n",
    "    \"ali\":     os.path.join(BASE, \"e-commerce-pet-supplies-dataset\", \"aliexpress_pet_supplies.csv\"),\n",
    "    \"usst\":    os.path.join(BASE, \"us-pet-food-supply-stores\", \"US Pet Food  Supply Stores.csv\"),\n",
    "    \"metrics\": os.path.join(BASE, \"sales-data-shop-pet\", \"metrics_2023-01-01_to_2023-08-10_targeted_interest.csv\"),\n",
    "}\n",
    "\n",
    "print(\"Loading CSVs...\")\n",
    "tails   = pd.read_csv(paths[\"tails\"])\n",
    "store   = pd.read_csv(paths[\"store\"])\n",
    "chewy   = pd.read_csv(paths[\"chewy\"])\n",
    "amz     = pd.read_csv(paths[\"amz\"])\n",
    "ali     = pd.read_csv(paths[\"ali\"])\n",
    "usst    = pd.read_csv(paths[\"usst\"])\n",
    "metrics = pd.read_csv(paths[\"metrics\"])\n",
    "\n",
    "dfs = {\n",
    "    \"tails\": tails,\n",
    "    \"store\": store,\n",
    "    \"chewy\": chewy,\n",
    "    \"amz\":   amz,\n",
    "    \"ali\":   ali,\n",
    "    \"usst\":  usst,\n",
    "    \"metrics\": metrics\n",
    "}\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    print(f\"{name:8s} ‚Üí {df.shape[0]:6d} rows √ó {df.shape[1]:3d} cols\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) QUICK EDA\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n=== BASIC EDA ===\")\n",
    "\n",
    "# 1.1 Tails orders\n",
    "print(\"\\n[TAILS] pet_food_customer_orders overview\")\n",
    "print(tails[['customer_id', 'pet_id', 'pet_order_number', 'pet_food_tier',\n",
    "             'wet_tray_size', 'wet_trays']].head())\n",
    "\n",
    "print(\"\\n[TAILS] pet_food_tier value counts:\")\n",
    "print(tails['pet_food_tier'].value_counts(dropna=False).head(10))\n",
    "\n",
    "print(\"\\n[TAILS] wet_tray_size value counts:\")\n",
    "print(tails['wet_tray_size'].value_counts(dropna=False).head(10))\n",
    "\n",
    "# 1.2 Store records\n",
    "print(\"\\n[STORE] pet_store_records_2020 overview\")\n",
    "print(store[['product_id', 'product_category', 'vendor_id', 'country',\n",
    "             'pet_type', 'pet_size', 'rating', 're_buy']].head())\n",
    "\n",
    "print(\"\\n[STORE] product_category value counts:\")\n",
    "print(store['product_category'].value_counts().head(10))\n",
    "\n",
    "print(\"\\n[STORE] pet_type value counts:\")\n",
    "print(store['pet_type'].value_counts().head(10))\n",
    "\n",
    "# 1.3 Chewy / Amazon / AliExpress (catalogs)\n",
    "print(\"\\n[CHEWY] sample:\")\n",
    "print(chewy[['name', 'brand', 'breadcrumb', 'Price', 'average_rating']].head(3))\n",
    "\n",
    "print(\"\\n[AMAZON] sample:\")\n",
    "print(amz[['title', 'brand', 'price', 'currency', 'breadcrumbs']].head(3))\n",
    "\n",
    "print(\"\\n[ALIEXPRESS] sample:\")\n",
    "print(ali.head(3))\n",
    "\n",
    "# 1.4 US pet food stores\n",
    "print(\"\\n[US Stores] sample:\")\n",
    "print(usst[['Business Name', 'City', 'State', 'Main Line of Business']].head(3))\n",
    "\n",
    "# 1.5 Metrics (ads / marketing)\n",
    "print(\"\\n[Metrics] columns:\")\n",
    "print(metrics.columns[:15])\n",
    "print(\"\\n[Metrics] sample:\")\n",
    "print(metrics.head(3))\n",
    "# ------------------------------------------------------------\n",
    "# 2) BUILD INTERACTION TABLE (TAILS + STORE) ‚Äî MORE GRANULAR\n",
    "# ------------------------------------------------------------\n",
    "# ------------------------------------------------------------\n",
    "# 2) BUILD INTERACTION TABLE (TAILS + STORE) ‚Äî MORE GRANULAR\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n=== BUILD INTERACTIONS ===\")\n",
    "\n",
    "# ---- 2.1 Tails interactions (customer ‚Üî detailed food-type) ----\n",
    "tails_small = tails.copy()\n",
    "\n",
    "# Fill important columns\n",
    "for col, default in [\n",
    "    ('pet_food_tier', 'unknown'),\n",
    "    ('wet_tray_size', 'none'),\n",
    "    ('pet_life_stage_at_order', 'unknown'),\n",
    "    ('pet_breed_size', 'unknown'),\n",
    "]:\n",
    "    if col in tails_small.columns:\n",
    "        tails_small[col] = tails_small[col].fillna(default).astype(str)\n",
    "    else:\n",
    "        # if a column is missing in your CSV, just create it as unknown\n",
    "        tails_small[col] = default\n",
    "\n",
    "# item_key: now 4 attributes ‚Üí many more unique \"recipes\"\n",
    "tails_small['item_key'] = (\n",
    "    \"tails_\"\n",
    "    + tails_small['pet_food_tier'] + \"|\"\n",
    "    + tails_small['wet_tray_size'] + \"|\"\n",
    "    + tails_small['pet_life_stage_at_order'] + \"|\"\n",
    "    + tails_small['pet_breed_size']\n",
    ")\n",
    "\n",
    "# user_key: customer\n",
    "tails_small['user_key'] = \"cust_\" + tails_small['customer_id'].astype(str)\n",
    "\n",
    "# weight from usage: we keep it simple but not just 1\n",
    "#   base = max(wet_trays, 1)\n",
    "#   small bonus if they've placed more orders for this pet's wet food\n",
    "tails_small['wet_trays_filled'] = tails_small['wet_trays'].fillna(0)\n",
    "base = tails_small['wet_trays_filled'].clip(lower=1)\n",
    "\n",
    "if 'orders_since_first_wet_trays_order' in tails_small.columns:\n",
    "    bonus = tails_small['orders_since_first_wet_trays_order'].fillna(0) * 0.1\n",
    "else:\n",
    "    bonus = 0\n",
    "\n",
    "tails_small['weight'] = (base + bonus).astype(float)\n",
    "\n",
    "tails_inter = (\n",
    "    tails_small[['user_key', 'item_key', 'weight']]\n",
    "    .groupby(['user_key', 'item_key'], as_index=False)['weight']\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "print(\"Interactions from Tails:\", tails_inter.shape)\n",
    "\n",
    "# ---- 2.2 Store interactions (vendor ‚Üî product) ----\n",
    "store_small = store.copy()\n",
    "store_small['item_key'] = \"store_\" + store_small['product_id'].astype(str)\n",
    "store_small['user_key'] = \"vendor_\" + store_small['vendor_id'].astype(str)\n",
    "\n",
    "# use re_buy as signal (repeated purchase), or at least 1 if anything\n",
    "store_small['weight'] = 1.0 + store_small['re_buy'].fillna(0)\n",
    "store_inter = (\n",
    "    store_small[['user_key', 'item_key', 'weight']]\n",
    "    .groupby(['user_key', 'item_key'], as_index=False)['weight']\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "print(\"Interactions from Store:\", store_inter.shape)\n",
    "\n",
    "# ---- 2.3 Combine ----\n",
    "interactions = pd.concat(\n",
    "    [\n",
    "        tails_inter[['user_key', 'item_key', 'weight']],\n",
    "        store_inter[['user_key', 'item_key', 'weight']],\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "print(\"Total interactions (raw):\", interactions.shape)\n",
    "\n",
    "# ---- 2.4 Filter low-activity (SOFTER on items) ----\n",
    "def filter_by_min_interactions(df, min_user=2, min_item=1):\n",
    "    \"\"\"\n",
    "    Keep users with >= min_user interactions;\n",
    "    keep items with >= min_item interactions.\n",
    "    (min_item=1 means we don't aggressively kill rare products.)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    while True:\n",
    "        uc = df['user_key'].value_counts()\n",
    "        ic = df['item_key'].value_counts()\n",
    "        before = df.shape[0]\n",
    "        df = df[df['user_key'].isin(uc[uc >= min_user].index)]\n",
    "        df = df[df['item_key'].isin(ic[ic >= min_item].index)]\n",
    "        after = df.shape[0]\n",
    "        if after == before:\n",
    "            break\n",
    "    return df\n",
    "\n",
    "interactions = filter_by_min_interactions(interactions,\n",
    "                                          min_user=2, min_item=1)\n",
    "print(\"Total interactions (filtered):\", interactions.shape)\n",
    "\n",
    "# small EDA on interactions\n",
    "print(\"\\nNumber of distinct users:\", interactions['user_key'].nunique())\n",
    "print(\"Number of distinct items:\", interactions['item_key'].nunique())\n",
    "print(\"Top 10 most popular items:\\n\",\n",
    "      (interactions.groupby('item_key')['weight'].sum()\n",
    "                  .sort_values(ascending=False)\n",
    "                  .head(10)))\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) ENCODE USERS/ITEMS\n",
    "# ------------------------------------------------------------\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "interactions['user_id'] = user_encoder.fit_transform(interactions['user_key'])\n",
    "interactions['item_id'] = item_encoder.fit_transform(interactions['item_key'])\n",
    "\n",
    "n_users = interactions['user_id'].nunique()\n",
    "n_items = interactions['item_id'].nunique()\n",
    "\n",
    "print(f\"\\nEncoded users: {n_users}, items: {n_items}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) TRAIN‚ÄìTEST SPLIT BY USER\n",
    "# ------------------------------------------------------------\n",
    "def train_test_split_by_user(df, test_size_per_user=1, random_state=42):\n",
    "    df = df.sort_values('user_id')\n",
    "    test_rows = []\n",
    "    train_rows = []\n",
    "    rng = np.random.RandomState(random_state)\n",
    "\n",
    "    for uid, group in df.groupby('user_id'):\n",
    "        if len(group) <= test_size_per_user:\n",
    "            train_rows.append(group)\n",
    "            continue\n",
    "        test_idx = rng.choice(group.index.values,\n",
    "                              size=test_size_per_user,\n",
    "                              replace=False)\n",
    "        test_mask = group.index.isin(test_idx)\n",
    "        test_rows.append(group[test_mask])\n",
    "        train_rows.append(group[~test_mask])\n",
    "\n",
    "    train_df = pd.concat(train_rows, ignore_index=True)\n",
    "    test_df  = pd.concat(test_rows,  ignore_index=True)\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = train_test_split_by_user(\n",
    "    interactions, test_size_per_user=1, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Train interactions:\", train_df.shape)\n",
    "print(\"Test interactions:\", test_df.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) BUILD SPARSE MATRICES\n",
    "# ------------------------------------------------------------\n",
    "def build_sparse_matrix(df, n_users, n_items):\n",
    "    return sp.coo_matrix(\n",
    "        (df['weight'].astype(float),\n",
    "         (df['user_id'].astype(int), df['item_id'].astype(int))),\n",
    "        shape=(n_users, n_items)\n",
    "    ).tocsr()\n",
    "\n",
    "train_mat = build_sparse_matrix(train_df, n_users, n_items)\n",
    "test_mat  = build_sparse_matrix(test_df,  n_users, n_items)\n",
    "\n",
    "print(\"Sparse shapes ‚Äî train:\", train_mat.shape, \"test:\", test_mat.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) BUILD UNIFIED ITEM CATALOG (USES CHEWY/AMZ/ALI TOO)\n",
    "# ------------------------------------------------------------\n",
    "# --- core items from tails & store ---\n",
    "cat_rows = []\n",
    "\n",
    "# tails\n",
    "temp_tails_items = tails_small[['item_key', 'pet_food_tier', 'wet_tray_size']].drop_duplicates()\n",
    "temp_tails_items['source'] = 'tails'\n",
    "temp_tails_items = temp_tails_items.rename(columns={\n",
    "    'pet_food_tier': 'category',\n",
    "    'wet_tray_size': 'size'\n",
    "})\n",
    "cat_rows.append(temp_tails_items[['item_key', 'source', 'category', 'size']])\n",
    "\n",
    "# store\n",
    "temp_store_items = store_small[['item_key', 'product_category', 'pet_type', 'pet_size']].drop_duplicates()\n",
    "temp_store_items['source'] = 'store'\n",
    "temp_store_items = temp_store_items.rename(columns={\n",
    "    'product_category': 'category',\n",
    "    'pet_size': 'size'\n",
    "})\n",
    "cat_rows.append(temp_store_items[['item_key', 'source', 'category', 'pet_type', 'size']])\n",
    "\n",
    "catalog_core = pd.concat(cat_rows, ignore_index=True).drop_duplicates('item_key')\n",
    "\n",
    "# --- extra items from Chewy / Amazon / AliExpress ---\n",
    "chewy_items = pd.DataFrame({\n",
    "    'item_key': \"chewy_\" + chewy['uniq_id'].astype(str),\n",
    "    'source':   'chewy',\n",
    "    'name':     chewy['name'],\n",
    "    'brand':    chewy['brand'],\n",
    "    'category': chewy['breadcrumb']\n",
    "})\n",
    "\n",
    "amz_items = pd.DataFrame({\n",
    "    'item_key': \"amz_\" + amz['asin'].astype(str),\n",
    "    'source':   'amazon',\n",
    "    'name':     amz['title'],\n",
    "    'brand':    amz['brand'],\n",
    "    'category': amz['breadcrumbs']\n",
    "})\n",
    "\n",
    "ali_items = pd.DataFrame({\n",
    "    'item_key': \"ali_\" + ali.index.astype(str),\n",
    "    'source':   'aliexpress',\n",
    "    'name':     ali['title'],\n",
    "    'brand':    np.nan,\n",
    "    'category': 'AliExpressPetSupplies'\n",
    "})\n",
    "\n",
    "catalog_extra = pd.concat([chewy_items, amz_items, ali_items], ignore_index=True)\n",
    "\n",
    "items_catalog = pd.concat([catalog_core, catalog_extra], ignore_index=True)\n",
    "items_catalog = items_catalog.drop_duplicates('item_key')\n",
    "\n",
    "items_catalog['item_id'] = -1\n",
    "mask_known = items_catalog['item_key'].isin(item_encoder.classes_)\n",
    "items_catalog.loc[mask_known, 'item_id'] = item_encoder.transform(\n",
    "    items_catalog.loc[mask_known, 'item_key']\n",
    ")\n",
    "\n",
    "print(\"\\nUnified item catalog size:\", items_catalog.shape)\n",
    "print(items_catalog.head())\n",
    "# ------------------------------------------------------------\n",
    "# 6b) SIMULATE INTERACTIONS FOR CHEWY / AMAZON / ALI\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "core_sources = [\"tails\", \"store\"]\n",
    "ext_sources  = [\"chewy\", \"amazon\", \"aliexpress\"]  # as defined above\n",
    "\n",
    "core_mask = items_catalog[\"source\"].isin(core_sources)\n",
    "ext_mask  = items_catalog[\"source\"].isin(ext_sources)\n",
    "\n",
    "print(\"Core items:\", core_mask.sum(), \"External items:\", ext_mask.sum())\n",
    "\n",
    "# 6b.1 Build simple text for each item (for content similarity)\n",
    "def build_item_text(row):\n",
    "    parts = []\n",
    "    for col in [\"category\", \"size\", \"pet_type\", \"name\", \"brand\"]:\n",
    "        if col in row and pd.notna(row[col]):\n",
    "            parts.append(str(row[col]))\n",
    "    return \" \".join(parts)\n",
    "\n",
    "items_catalog[\"text\"] = items_catalog.apply(build_item_text, axis=1).fillna(\"\")\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(items_catalog[\"text\"])\n",
    "\n",
    "core_idx = np.where(core_mask)[0]\n",
    "ext_idx  = np.where(ext_mask)[0]\n",
    "\n",
    "X_core = X[core_idx]\n",
    "X_ext  = X[ext_idx]\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sim_ext_core = cosine_similarity(X_ext, X_core)  # [n_ext, n_core]\n",
    "print(\"Similarity matrix shape:\", sim_ext_core.shape)\n",
    "\n",
    "# 6b.2 Map core items -> real users\n",
    "item_to_users = (\n",
    "    interactions\n",
    "    .groupby(\"item_key\")[\"user_key\"]\n",
    "    .apply(list)\n",
    "    .to_dict()\n",
    ")\n",
    "print(\"Number of core items with real users:\", len(item_to_users))\n",
    "\n",
    "# 6b.3 Generate synthetic interactions\n",
    "rng = np.random.RandomState(123)\n",
    "\n",
    "K_SIM = 5              # top-K similar core items\n",
    "MAX_USERS_PER_EXT = 20 # max synthetic users per external item\n",
    "MIN_WEIGHT = 0.1       # avoid 0\n",
    "scale_weight = 3.0     # similarity -> implicit weight\n",
    "\n",
    "synthetic_rows = []  # (user_key, item_key, weight)\n",
    "\n",
    "for ext_pos, row_idx in enumerate(ext_idx):\n",
    "    ext_row = items_catalog.iloc[row_idx]\n",
    "    ext_key = ext_row[\"item_key\"]\n",
    "    sims = sim_ext_core[ext_pos]\n",
    "    if np.all(sims <= 0):\n",
    "        continue\n",
    "\n",
    "    top_core_local = np.argsort(-sims)[:K_SIM]\n",
    "    used_users = set()\n",
    "\n",
    "    for local_idx in top_core_local:\n",
    "        core_global_idx = core_idx[local_idx]\n",
    "        core_key = items_catalog.iloc[core_global_idx][\"item_key\"]\n",
    "        users = item_to_users.get(core_key, [])\n",
    "        if not users:\n",
    "            continue\n",
    "\n",
    "        n_users = len(users)\n",
    "        sample_size = max(1, min(n_users, n_users // 10))\n",
    "        sampled_users = rng.choice(users, size=sample_size, replace=False)\n",
    "\n",
    "        sim_val = float(sims[local_idx])  # [0,1]\n",
    "        base_w  = max(MIN_WEIGHT, sim_val * scale_weight)\n",
    "\n",
    "        for u in sampled_users:\n",
    "            if u in used_users:\n",
    "                continue\n",
    "            used_users.add(u)\n",
    "            synthetic_rows.append((u, ext_key, base_w))\n",
    "\n",
    "        if len(used_users) >= MAX_USERS_PER_EXT:\n",
    "            break\n",
    "\n",
    "print(\"Synthetic interactions generated:\", len(synthetic_rows))\n",
    "\n",
    "synthetic_df = pd.DataFrame(\n",
    "    synthetic_rows,\n",
    "    columns=[\"user_key\", \"item_key\", \"weight\"]\n",
    ")\n",
    "\n",
    "# 6b.4 Merge synthetic with real interactions\n",
    "interactions_aug = pd.concat(\n",
    "    [interactions[[\"user_key\", \"item_key\", \"weight\"]], synthetic_df],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "print(\"Original interactions:\", interactions.shape)\n",
    "print(\"Augmented interactions:\", interactions_aug.shape)\n",
    "\n",
    "# reuse your existing filter_by_min_interactions (already defined above)\n",
    "interactions_aug = filter_by_min_interactions(\n",
    "    interactions_aug,\n",
    "    min_user=2,\n",
    "    min_item=1   # keep rare external products\n",
    ")\n",
    "print(\"Augmented interactions after filtering:\", interactions_aug.shape)\n",
    "\n",
    "# From now on, we work with the augmented interactions\n",
    "interactions = interactions_aug\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7) ENCODE USERS/ITEMS (AFTER AUGMENTATION)\n",
    "# ------------------------------------------------------------\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "interactions[\"user_id\"] = user_encoder.fit_transform(interactions[\"user_key\"])\n",
    "interactions[\"item_id\"] = item_encoder.fit_transform(interactions[\"item_key\"])\n",
    "\n",
    "n_users = interactions[\"user_id\"].nunique()\n",
    "n_items = interactions[\"item_id\"].nunique()\n",
    "\n",
    "print(f\"\\nEncoded users (augmented): {n_users}, items: {n_items}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8) TRAIN‚ÄìTEST SPLIT BY USER (SAME AS BEFORE)\n",
    "# ------------------------------------------------------------\n",
    "train_df, test_df = train_test_split_by_user(\n",
    "    interactions, test_size_per_user=1, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Train interactions:\", train_df.shape)\n",
    "print(\"Test interactions:\", test_df.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9) BUILD SPARSE MATRICES (AUGMENTED)\n",
    "# ------------------------------------------------------------\n",
    "train_mat = build_sparse_matrix(train_df, n_users, n_items)\n",
    "test_mat  = build_sparse_matrix(test_df,  n_users, n_items)\n",
    "\n",
    "print(\"Sparse shapes ‚Äî train:\", train_mat.shape, \"test:\", test_mat.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7) EVALUATION METRICS (Recall@K, MAP@K)\n",
    "# ------------------------------------------------------------\n",
    "def recall_at_k(recommender_fn, train_mat, test_mat, k=10, n_users_eval=None):\n",
    "    \"\"\"\n",
    "    recommender_fn: function(user_id, N) -> list/array of recommended item_ids\n",
    "    \"\"\"\n",
    "    n_users, _ = train_mat.shape\n",
    "    if n_users_eval is None or n_users_eval > n_users:\n",
    "        n_users_eval = n_users\n",
    "\n",
    "    recalls = []\n",
    "    for u in range(n_users_eval):\n",
    "        test_items = test_mat[u].indices\n",
    "        if len(test_items) == 0:\n",
    "            continue\n",
    "        rec_items = recommender_fn(u, k)\n",
    "        hits = len(set(test_items) & set(rec_items))\n",
    "        recalls.append(hits / len(test_items))\n",
    "    return float(np.mean(recalls)) if len(recalls) > 0 else np.nan\n",
    "\n",
    "def map_at_k(recommender_fn, train_mat, test_mat, k=10, n_users_eval=None):\n",
    "    n_users, _ = train_mat.shape\n",
    "    if n_users_eval is None or n_users_eval > n_users:\n",
    "        n_users_eval = n_users\n",
    "\n",
    "    aps = []\n",
    "    for u in range(n_users_eval):\n",
    "        test_items = test_mat[u].indices\n",
    "        if len(test_items) == 0:\n",
    "            continue\n",
    "        rec_items = recommender_fn(u, k)\n",
    "\n",
    "        score = 0.0\n",
    "        hits = 0\n",
    "        for i, item in enumerate(rec_items, start=1):\n",
    "            if item in test_items:\n",
    "                hits += 1\n",
    "                score += hits / i\n",
    "        if hits > 0:\n",
    "            aps.append(score / min(len(test_items), k))\n",
    "        else:\n",
    "            aps.append(0.0)\n",
    "    return float(np.mean(aps)) if len(aps) > 0 else np.nan\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8) MODEL 1 ‚Äî POPULARITY BASELINE\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n=== MODEL 1: Popularity baseline ===\")\n",
    "item_popularity = np.asarray(train_mat.sum(axis=0)).ravel()\n",
    "popular_items_sorted = np.argsort(-item_popularity)  # descending\n",
    "\n",
    "def pop_recommender(user_id, N=10):\n",
    "    # filter out items the user already interacted with\n",
    "    known_items = set(train_mat[user_id].indices)\n",
    "    rec = [i for i in popular_items_sorted if i not in known_items]\n",
    "    return rec[:N]\n",
    "\n",
    "pop_recall10 = recall_at_k(pop_recommender, train_mat, test_mat, k=10, n_users_eval=2000)\n",
    "pop_map10    = map_at_k(pop_recommender,    train_mat, test_mat, k=10, n_users_eval=2000)\n",
    "print(f\"Popularity ‚Üí Recall@10 = {pop_recall10:.4f}, MAP@10 = {pop_map10:.4f}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9) MODEL 2 ‚Äî Item-Item kNN (Collaborative)\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n=== MODEL 2: Item-kNN (cosine) ===\")\n",
    "\n",
    "\n",
    "# item vectors = columns of train_mat  ‚Üí (n_items x n_users)\n",
    "item_user = train_mat.T.tocsr()\n",
    "item_user_norm = normalize(item_user, axis=1)\n",
    "# cosine similarity matrix between items ‚Üí (n_items x n_items)\n",
    "item_sim = (item_user_norm @ item_user_norm.T).tocsr()\n",
    "item_sim.setdiag(0)\n",
    "\n",
    "# For our tiny n_items, we can safely use a dense matrix\n",
    "item_sim_dense = item_sim.toarray()\n",
    "\n",
    "def itemknn_recommender(user_id, N=10):\n",
    "    user_row = train_mat[user_id]              # (1 x n_items) sparse\n",
    "    user_items = user_row.indices              # indices of items user has\n",
    "    if len(user_items) == 0:\n",
    "        # cold-start user ‚Üí fall back to popularity\n",
    "        return pop_recommender(user_id, N)\n",
    "\n",
    "    # weights for the items this user has interacted with\n",
    "    user_weights_full = np.asarray(user_row.toarray()).ravel()\n",
    "    user_weights = user_weights_full[user_items]   # shape (|user_items|,)\n",
    "\n",
    "    # scores for each candidate item:\n",
    "    #   score(i) = sum_j sim(i, j) * weight_j  for j in user_items\n",
    "    # item_sim_dense: (n_items x n_items)\n",
    "    # take only columns of items user has\n",
    "    scores = item_sim_dense[:, user_items] @ user_weights   # (n_items,)\n",
    "\n",
    "    # don't recommend items the user already has\n",
    "    scores[user_items] = -np.inf\n",
    "\n",
    "    # top-N items by score\n",
    "    rec_items = np.argsort(-scores)[:N]\n",
    "    return rec_items\n",
    "\n",
    "\n",
    "knn_recall10 = recall_at_k(itemknn_recommender, train_mat, test_mat, k=10, n_users_eval=2000)\n",
    "knn_map10    = map_at_k(itemknn_recommender,    train_mat, test_mat, k=10, n_users_eval=2000)\n",
    "print(f\"Item-kNN   ‚Üí Recall@10 = {knn_recall10:.4f}, MAP@10 = {knn_map10:.4f}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 10) MODEL 3 ‚Äî ALS (Matrix Factorization with implicit)\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n=== MODEL 3: ALS (implicit) ===\")\n",
    "\n",
    "als_model = implicit.als.AlternatingLeastSquares(\n",
    "    factors=64,\n",
    "    regularization=0.01,\n",
    "    iterations=15,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# implicit expects user_items (users x items)\n",
    "user_item_mat = train_mat.tocsr()\n",
    "als_model.fit(user_item_mat)\n",
    "print(\"ALS training done.\")\n",
    "\n",
    "def als_recommender(user_id, N=10):\n",
    "    user_items = user_item_mat[user_id]\n",
    "    item_ids, scores = als_model.recommend(\n",
    "        userid=user_id,\n",
    "        user_items=user_items,\n",
    "        N=N,\n",
    "        filter_already_liked_items=True\n",
    "    )\n",
    "    return item_ids\n",
    "\n",
    "als_recall10 = recall_at_k(als_recommender, train_mat, test_mat, k=10, n_users_eval=2000)\n",
    "als_map10    = map_at_k(als_recommender,    train_mat, test_mat, k=10, n_users_eval=2000)\n",
    "print(f\"ALS        ‚Üí Recall@10 = {als_recall10:.4f}, MAP@10 = {als_map10:.4f}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 11) MODEL COMPARISON SUMMARY\n",
    "# ------------------------------------------------------------\n",
    "summary = pd.DataFrame({\n",
    "    \"model\": [\"Popularity\", \"Item-kNN\", \"ALS\"],\n",
    "    \"Recall@10\": [pop_recall10, knn_recall10, als_recall10],\n",
    "    \"MAP@10\":    [pop_map10,   knn_map10,   als_map10],\n",
    "})\n",
    "print(\"\\n=== MODEL COMPARISON ===\")\n",
    "print(summary)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 12) EXAMPLE PERSONALIZED RECOMMENDATIONS\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n=== EXAMPLE RECOMMENDATIONS (ALS) ===\")\n",
    "example_customer = tails_small['customer_id'].iloc[0]\n",
    "raw_user_key = \"cust_\" + str(example_customer)\n",
    "\n",
    "if raw_user_key in user_encoder.classes_:\n",
    "    uid = user_encoder.transform([raw_user_key])[0]\n",
    "    rec_items = als_recommender(uid, N=10)\n",
    "    rec_keys  = item_encoder.inverse_transform(rec_items)\n",
    "\n",
    "    rec_df = items_catalog[items_catalog['item_key'].isin(rec_keys)].copy()\n",
    "    rec_df['rank'] = rec_df['item_key'].map({k: i for i, k in enumerate(rec_keys)})\n",
    "    rec_df = rec_df.sort_values('rank').reset_index(drop=True)\n",
    "\n",
    "    print(f\"Recommendations for customer_id={example_customer}:\")\n",
    "    print(rec_df[['item_key', 'source', 'category', 'size']].head(10))\n",
    "else:\n",
    "    print(f\"Customer {example_customer} not in training set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:47:59.899358Z",
     "iopub.status.busy": "2025-11-14T14:47:59.898533Z",
     "iopub.status.idle": "2025-11-14T14:48:10.295275Z",
     "shell.execute_reply": "2025-11-14T14:48:10.293992Z",
     "shell.execute_reply.started": "2025-11-14T14:47:59.899333Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48/3835960981.py:25: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv_sqrt = np.power(rowsum, -0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LightGCN...\n",
      "Epoch 1/5 - loss: 0.6931\n",
      "Epoch 2/5 - loss: 0.6930\n",
      "Epoch 3/5 - loss: 0.6929\n",
      "Epoch 4/5 - loss: 0.6928\n",
      "Epoch 5/5 - loss: 0.6926\n",
      "\n",
      "LightGCN  ‚Üí Recall@10 = 0.2050, MAP@10 = 0.0792\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# A) GRAPH-BASED MODEL ‚Äî LightGCN style\n",
    "# =========================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import scipy.sparse as sp\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Build normalized adjacency A_hat for user‚Äìitem graph\n",
    "R = train_mat  # (n_users x n_items)\n",
    "num_users, num_items = R.shape\n",
    "num_nodes = num_users + num_items\n",
    "\n",
    "# Adjacency: [[0, R],\n",
    "#             [R^T, 0]]\n",
    "upper = sp.hstack([sp.csr_matrix((num_users, num_users)), R])\n",
    "lower = sp.hstack([R.T, sp.csr_matrix((num_items, num_items))])\n",
    "A = sp.vstack([upper, lower]).tocsr()\n",
    "\n",
    "# D^{-1/2} A D^{-1/2}\n",
    "rowsum = np.array(A.sum(axis=1)).flatten()\n",
    "d_inv_sqrt = np.power(rowsum, -0.5)\n",
    "d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "D_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "A_hat = D_inv_sqrt.dot(A).dot(D_inv_sqrt).tocsr()\n",
    "\n",
    "# Convert to torch sparse\n",
    "A_hat_coo = A_hat.tocoo()\n",
    "indices = torch.from_numpy(\n",
    "    np.vstack([A_hat_coo.row, A_hat_coo.col]).astype(np.int64)\n",
    ")\n",
    "values = torch.from_numpy(A_hat_coo.data.astype(np.float32))\n",
    "A_hat_torch = torch.sparse_coo_tensor(\n",
    "    indices, values, (num_nodes, num_nodes), device=device\n",
    ").coalesce()\n",
    "\n",
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=32, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.user_emb = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_emb = nn.Embedding(num_items, embedding_dim)\n",
    "        nn.init.normal_(self.user_emb.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_emb.weight, std=0.01)\n",
    "\n",
    "    def propagate(self):\n",
    "        all_emb = torch.cat(\n",
    "            [self.user_emb.weight, self.item_emb.weight], dim=0\n",
    "        )  # (num_nodes, d)\n",
    "        embs = [all_emb]\n",
    "\n",
    "        for _ in range(self.num_layers):\n",
    "            all_emb = torch.sparse.mm(A_hat_torch, all_emb)\n",
    "            embs.append(all_emb)\n",
    "\n",
    "        # Mean over layers\n",
    "        embs = torch.stack(embs, dim=0).mean(dim=0)\n",
    "        user_final = embs[:self.num_users]\n",
    "        item_final = embs[self.num_users:]\n",
    "        return user_final, item_final\n",
    "\n",
    "    def forward(self, users, pos_items, neg_items):\n",
    "        user_final, item_final = self.propagate()\n",
    "        u = user_final[users]\n",
    "        p = item_final[pos_items]\n",
    "        n = item_final[neg_items]\n",
    "\n",
    "        pos_scores = (u * p).sum(dim=-1)\n",
    "        neg_scores = (u * n).sum(dim=-1)\n",
    "\n",
    "        # BPR loss + small L2 regularization\n",
    "        loss = -torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-8).mean()\n",
    "        reg = (u.norm(2).pow(2) + p.norm(2).pow(2) + n.norm(2).pow(2)) / users.size(0)\n",
    "        return loss + 1e-4 * reg\n",
    "\n",
    "# Build training triples (u, i, j)\n",
    "all_items = np.arange(num_items)\n",
    "\n",
    "user_pos_items = {}\n",
    "for uid, group in train_df.groupby('user_id'):\n",
    "    user_pos_items[uid] = group['item_id'].values\n",
    "\n",
    "def sample_batch(batch_size=1024):\n",
    "    users = []\n",
    "    pos = []\n",
    "    neg = []\n",
    "    for _ in range(batch_size):\n",
    "        u = np.random.randint(0, num_users)\n",
    "        pos_items = user_pos_items.get(u, None)\n",
    "        if pos_items is None or len(pos_items) == 0:\n",
    "            continue\n",
    "        i = np.random.choice(pos_items)\n",
    "        # sample negative item\n",
    "        j = np.random.choice(all_items)\n",
    "        while j in pos_items:\n",
    "            j = np.random.choice(all_items)\n",
    "        users.append(u)\n",
    "        pos.append(i)\n",
    "        neg.append(j)\n",
    "    return (\n",
    "        torch.tensor(users, dtype=torch.long, device=device),\n",
    "        torch.tensor(pos,   dtype=torch.long, device=device),\n",
    "        torch.tensor(neg,   dtype=torch.long, device=device),\n",
    "    )\n",
    "\n",
    "lightgcn = LightGCN(num_users, num_items, embedding_dim=32, num_layers=2).to(device)\n",
    "optimizer = optim.Adam(lightgcn.parameters(), lr=1e-3)\n",
    "\n",
    "print(\"\\nTraining LightGCN...\")\n",
    "for epoch in range(5):  # small number of epochs for demo\n",
    "    lightgcn.train()\n",
    "    users_b, pos_b, neg_b = sample_batch(batch_size=2048)\n",
    "    if users_b.numel() == 0:\n",
    "        continue\n",
    "    loss = lightgcn(users_b, pos_b, neg_b)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/5 - loss: {loss.item():.4f}\")\n",
    "\n",
    "lightgcn.eval()\n",
    "with torch.no_grad():\n",
    "    lg_user_emb, lg_item_emb = lightgcn.propagate()\n",
    "lg_user_emb = lg_user_emb.cpu().numpy()\n",
    "lg_item_emb = lg_item_emb.cpu().numpy()\n",
    "\n",
    "def lightgcn_recommender(user_id, N=10):\n",
    "    scores = lg_item_emb @ lg_user_emb[user_id]  # (n_items,)\n",
    "    known = train_mat[user_id].indices\n",
    "    scores[known] = -np.inf\n",
    "    return np.argsort(-scores)[:N]\n",
    "\n",
    "lg_recall10 = recall_at_k(lightgcn_recommender, train_mat, test_mat, k=10, n_users_eval=2000)\n",
    "lg_map10    = map_at_k(lightgcn_recommender,    train_mat, test_mat, k=10, n_users_eval=2000)\n",
    "print(f\"\\nLightGCN  ‚Üí Recall@10 = {lg_recall10:.4f}, MAP@10 = {lg_map10:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:48:10.297545Z",
     "iopub.status.busy": "2025-11-14T14:48:10.296891Z",
     "iopub.status.idle": "2025-11-14T14:48:12.278911Z",
     "shell.execute_reply": "2025-11-14T14:48:12.277952Z",
     "shell.execute_reply.started": "2025-11-14T14:48:10.297511Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hybrid (ALS+Content) ‚Üí Recall@10 = 0.0145, MAP@10 = 0.0084\n",
      "\n",
      "Hybrid recommendations for customer_id= 10574848487411271014\n",
      "                                       item_key source      category  size\n",
      "0          tails_superpremium|none|senior|large  tails  superpremium  none\n",
      "1   tails_superpremium|none|half_maturity|giant  tails  superpremium  none\n",
      "2         tails_superpremium|none|weaning|large  tails  superpremium  none\n",
      "3           tails_superpremium|none|weaning|toy  tails  superpremium  none\n",
      "4     tails_superpremium|none|half_maturity|toy  tails  superpremium  none\n",
      "5   tails_superpremium|none|half_maturity|large  tails  superpremium  none\n",
      "6          tails_superpremium|none|mature|small  tails  superpremium  none\n",
      "7  tails_superpremium|none|half_maturity|medium  tails  superpremium  none\n",
      "8         tails_superpremium|none|mature|medium  tails  superpremium  none\n",
      "9            tails_superpremium|none|mature|toy  tails  superpremium  none\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# B) HYBRID CF + CONTENT-BASED MODEL\n",
    "# =========================================\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize as skl_normalize\n",
    "\n",
    "# 1) Make sure items_catalog has item_id aligned with CURRENT item_encoder\n",
    "items_catalog['item_id'] = -1\n",
    "mask_known_items = items_catalog['item_key'].isin(item_encoder.classes_)\n",
    "items_catalog.loc[mask_known_items, 'item_id'] = item_encoder.transform(\n",
    "    items_catalog.loc[mask_known_items, 'item_key']\n",
    ")\n",
    "\n",
    "# Keep only items that actually exist in the user‚Äìitem matrix\n",
    "catalog_for_matrix = items_catalog[items_catalog['item_id'] >= 0].copy()\n",
    "\n",
    "# Sort by item_id and ensure row index matches item_id\n",
    "catalog_for_matrix = catalog_for_matrix.sort_values('item_id')\n",
    "# texts indexed by item_id: index 0..n_items-1\n",
    "texts = catalog_for_matrix.set_index('item_id').loc[range(n_items), :]['text' if 'text' in catalog_for_matrix.columns else None]\n",
    "\n",
    "# If you didn't build \"text\" before, build it now:\n",
    "if 'text' not in catalog_for_matrix.columns:\n",
    "    def make_item_text(row):\n",
    "        parts = [\n",
    "            str(row.get('source', '')),\n",
    "            str(row.get('category', '')),\n",
    "            str(row.get('size', '')),\n",
    "            str(row.get('pet_type', '')),\n",
    "            str(row.get('name', '')),\n",
    "            str(row.get('brand', '')),\n",
    "        ]\n",
    "        return \" \".join([p for p in parts if p and p != 'nan'])\n",
    "    catalog_for_matrix['text'] = catalog_for_matrix.apply(make_item_text, axis=1)\n",
    "    texts = catalog_for_matrix.set_index('item_id').loc[range(n_items), 'text']\n",
    "\n",
    "# 2) TF‚ÄìIDF for ALL items in matrix (rows = item_id)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(texts.fillna(''))\n",
    "X_tfidf = skl_normalize(X_tfidf)   # shape: (n_items, d)\n",
    "assert X_tfidf.shape[0] == n_items, \"TF-IDF rows must match n_items\"\n",
    "\n",
    "# 3) Hybrid recommender: alpha * ALS + (1-alpha) * content-based\n",
    "def hybrid_recommender(user_id, alpha=0.6, N=10):\n",
    "    user_row = train_mat[user_id]\n",
    "    user_items = user_row.indices\n",
    "\n",
    "    if len(user_items) == 0:\n",
    "        # cold-start ‚Üí popularity\n",
    "        return pop_recommender(user_id, N)\n",
    "\n",
    "    # (a) CF scores from ALS\n",
    "    cf_scores = als_model.item_factors @ als_model.user_factors[user_id]  # (n_items,)\n",
    "\n",
    "    # (b) Content-based profile from TF‚ÄìIDF\n",
    "    weights_full = np.asarray(user_row.toarray()).ravel()\n",
    "    w = weights_full[user_items]\n",
    "    if w.sum() == 0:\n",
    "        w = np.ones_like(w)\n",
    "\n",
    "    # profile_vec in TF‚ÄìIDF space\n",
    "    profile_vec = (X_tfidf[user_items].T @ w).ravel()\n",
    "    norm = np.linalg.norm(profile_vec)\n",
    "    if norm > 0:\n",
    "        profile_vec = profile_vec / norm\n",
    "\n",
    "    cb_scores = (X_tfidf @ profile_vec).ravel()  # (n_items,)\n",
    "\n",
    "    # (c) Combine scores (same length)\n",
    "    scores = alpha * cf_scores + (1.0 - alpha) * cb_scores\n",
    "\n",
    "    # do not recommend already seen items\n",
    "    scores[user_items] = -np.inf\n",
    "\n",
    "    return np.argsort(-scores)[:N]\n",
    "\n",
    "# 4) Evaluate hybrid model\n",
    "hybrid_recall10 = recall_at_k(hybrid_recommender, train_mat, test_mat, k=10, n_users_eval=2000)\n",
    "hybrid_map10    = map_at_k(hybrid_recommender,    train_mat, test_mat, k=10, n_users_eval=2000)\n",
    "print(f\"\\nHybrid (ALS+Content) ‚Üí Recall@10 = {hybrid_recall10:.4f}, MAP@10 = {hybrid_map10:.4f}\")\n",
    "\n",
    "# 5) Example hybrid recommendations for same customer\n",
    "print(\"\\nHybrid recommendations for customer_id=\", example_customer)\n",
    "if raw_user_key in user_encoder.classes_:\n",
    "    uid = user_encoder.transform([raw_user_key])[0]\n",
    "    rec_items = hybrid_recommender(uid, N=10)\n",
    "    rec_keys  = item_encoder.inverse_transform(rec_items)\n",
    "    rec_df = items_catalog[items_catalog['item_key'].isin(rec_keys)].copy()\n",
    "    rec_df['rank'] = rec_df['item_key'].map({k: i for i, k in enumerate(rec_keys)})\n",
    "    rec_df = rec_df.sort_values('rank').reset_index(drop=True)\n",
    "    print(rec_df[['item_key', 'source', 'category', 'size']].head(10))\n",
    "else:\n",
    "    print(f\"Customer {example_customer} not in training set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:48:12.280575Z",
     "iopub.status.busy": "2025-11-14T14:48:12.280166Z",
     "iopub.status.idle": "2025-11-14T14:48:18.211715Z",
     "shell.execute_reply": "2025-11-14T14:48:18.210412Z",
     "shell.execute_reply.started": "2025-11-14T14:48:12.280545Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CVAE...\n",
      "Epoch 1/10 - loss: 111.0272\n",
      "Epoch 2/10 - loss: 100.9457\n",
      "Epoch 3/10 - loss: 89.3288\n",
      "Epoch 4/10 - loss: 74.9731\n",
      "Epoch 5/10 - loss: 55.6572\n",
      "Epoch 6/10 - loss: 35.2388\n",
      "Epoch 7/10 - loss: 22.8565\n",
      "Epoch 8/10 - loss: 18.3884\n",
      "Epoch 9/10 - loss: 16.6303\n",
      "Epoch 10/10 - loss: 15.5306\n",
      "\n",
      "CVAE      ‚Üí Recall@10 = 0.2685, MAP@10 = 0.0985\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# C) CVAE MODEL (user ‚Üí latent ‚Üí reconstructed items)\n",
    "# =========================================\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class UserItemDataset(Dataset):\n",
    "    def __init__(self, mat):\n",
    "        self.mat = mat\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.mat.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = np.asarray(self.mat[idx].toarray()).ravel().astype('float32')\n",
    "        row[row > 0] = 1.0  # binarize\n",
    "        return torch.from_numpy(row)\n",
    "\n",
    "train_dataset = UserItemDataset(train_mat)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, n_items, hidden_dim=32, latent_dim=16):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_items, hidden_dim)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_dec1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc_out = nn.Linear(hidden_dim, n_items)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = torch.relu(self.fc1(x))\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = torch.relu(self.fc_dec1(z))\n",
    "        return torch.sigmoid(self.fc_out(h))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, mu, logvar\n",
    "\n",
    "def vae_loss(x, x_recon, mu, logvar):\n",
    "    # BCE reconstruction\n",
    "    bce = nn.functional.binary_cross_entropy(x_recon, x, reduction='sum')\n",
    "    # KL divergence\n",
    "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return (bce + kld) / x.size(0)\n",
    "\n",
    "cvae = CVAE(n_items, hidden_dim=32, latent_dim=16).to(device)\n",
    "optimizer_cvae = optim.Adam(cvae.parameters(), lr=1e-3)\n",
    "\n",
    "print(\"\\nTraining CVAE...\")\n",
    "for epoch in range(10):\n",
    "    cvae.train()\n",
    "    epoch_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        x_recon, mu, logvar = cvae(batch)\n",
    "        loss = vae_loss(batch, x_recon, mu, logvar)\n",
    "        optimizer_cvae.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_cvae.step()\n",
    "        epoch_loss += loss.item() * batch.size(0)\n",
    "    epoch_loss /= len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}/10 - loss: {epoch_loss:.4f}\")\n",
    "\n",
    "cvae.eval()\n",
    "\n",
    "def cvae_recommender(user_id, N=10):\n",
    "    row = np.asarray(train_mat[user_id].toarray()).ravel().astype('float32')\n",
    "    x = torch.from_numpy(row).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        x_recon, _, _ = cvae(x)\n",
    "    scores = x_recon.cpu().numpy().ravel()\n",
    "    known = train_mat[user_id].indices\n",
    "    scores[known] = -np.inf\n",
    "    return np.argsort(-scores)[:N]\n",
    "\n",
    "cvae_recall10 = recall_at_k(cvae_recommender, train_mat, test_mat, k=10, n_users_eval=2000)\n",
    "cvae_map10    = map_at_k(cvae_recommender,    train_mat, test_mat, k=10, n_users_eval=2000)\n",
    "print(f\"\\nCVAE      ‚Üí Recall@10 = {cvae_recall10:.4f}, MAP@10 = {cvae_map10:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:48:18.213142Z",
     "iopub.status.busy": "2025-11-14T14:48:18.212818Z",
     "iopub.status.idle": "2025-11-14T14:48:18.222575Z",
     "shell.execute_reply": "2025-11-14T14:48:18.221621Z",
     "shell.execute_reply.started": "2025-11-14T14:48:18.213106Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ALL MODELS COMPARISON ===\n",
      "                model  Recall@10    MAP@10\n",
      "0          Popularity     0.1215  0.050592\n",
      "1            Item-kNN     0.6930  0.365411\n",
      "2                 ALS     0.3605  0.202511\n",
      "3            LightGCN     0.2050  0.079232\n",
      "4  Hybrid ALS+Content     0.0145  0.008391\n",
      "5                CVAE     0.2685  0.098537\n"
     ]
    }
   ],
   "source": [
    "all_models_summary = pd.DataFrame({\n",
    "    \"model\": [\n",
    "        \"Popularity\",\n",
    "        \"Item-kNN\",\n",
    "        \"ALS\",\n",
    "        \"LightGCN\",\n",
    "        \"Hybrid ALS+Content\",\n",
    "        \"CVAE\"\n",
    "    ],\n",
    "    \"Recall@10\": [\n",
    "        pop_recall10,\n",
    "        knn_recall10,\n",
    "        als_recall10,\n",
    "        lg_recall10,\n",
    "        hybrid_recall10,\n",
    "        cvae_recall10\n",
    "    ],\n",
    "    \"MAP@10\": [\n",
    "        pop_map10,\n",
    "        knn_map10,\n",
    "        als_map10,\n",
    "        lg_map10,\n",
    "        hybrid_map10,\n",
    "        cvae_map10\n",
    "    ]\n",
    "})\n",
    "print(\"\\n=== ALL MODELS COMPARISON ===\")\n",
    "print(all_models_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:48:18.225782Z",
     "iopub.status.busy": "2025-11-14T14:48:18.225432Z",
     "iopub.status.idle": "2025-11-14T14:48:18.291030Z",
     "shell.execute_reply": "2025-11-14T14:48:18.289587Z",
     "shell.execute_reply.started": "2025-11-14T14:48:18.225746Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ALL MODELS COMPARISON (with simple product score) ===\n",
      "                model  Recall@10    MAP@10  Score_product\n",
      "0          Popularity     0.1215  0.050592       0.006147\n",
      "1            Item-kNN     0.6930  0.365411       0.253230\n",
      "2                 ALS     0.3605  0.202511       0.073005\n",
      "3            LightGCN     0.2050  0.079232       0.016243\n",
      "4  Hybrid ALS+Content     0.0145  0.008391       0.000122\n",
      "5                CVAE     0.2685  0.098537       0.026457\n"
     ]
    }
   ],
   "source": [
    "# Add a simple combined score = Recall@10 √ó MAP@10\n",
    "all_models_summary[\"Score_product\"] = (\n",
    "    all_models_summary[\"Recall@10\"] * all_models_summary[\"MAP@10\"]\n",
    ")\n",
    "\n",
    "print(\"\\n=== ALL MODELS COMPARISON (with simple product score) ===\")\n",
    "print(all_models_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:48:18.292488Z",
     "iopub.status.busy": "2025-11-14T14:48:18.292155Z",
     "iopub.status.idle": "2025-11-14T14:48:18.314329Z",
     "shell.execute_reply": "2025-11-14T14:48:18.313147Z",
     "shell.execute_reply.started": "2025-11-14T14:48:18.292458Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def timed_eval(model_name, recommender_fn, k=10, n_users_eval=2000):\n",
    "    start = time.perf_counter()\n",
    "    rec = recall_at_k(recommender_fn, train_mat, test_mat, k=k, n_users_eval=n_users_eval)\n",
    "    m   = map_at_k(recommender_fn,    train_mat, test_mat, k=k, n_users_eval=n_users_eval)\n",
    "    elapsed = time.perf_counter() - start\n",
    "    print(f\"{model_name}: Recall@{k}={rec:.4f}, MAP@{k}={m:.4f}, \"\n",
    "          f\"product={rec*m:.4f}, time={elapsed:.3f}s\")\n",
    "    return rec, m, elapsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:48:18.315862Z",
     "iopub.status.busy": "2025-11-14T14:48:18.315460Z",
     "iopub.status.idle": "2025-11-14T14:48:26.598632Z",
     "shell.execute_reply": "2025-11-14T14:48:26.597762Z",
     "shell.execute_reply.started": "2025-11-14T14:48:18.315836Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TIMED EVALUATION FOR ALL MODELS ===\n",
      "Popularity        : Recall@10=0.1215, MAP@10=0.0506, product=0.00614693571428571311487942807616491336375475, time=0.7734s\n",
      "Item-kNN          : Recall@10=0.6930, MAP@10=0.3654, product=0.25322976249999995523864981805672869086265564, time=0.7812s\n",
      "ALS               : Recall@10=0.3605, MAP@10=0.2025, product=0.07300525555555555101694409358970005996525288, time=1.1267s\n",
      "LightGCN          : Recall@10=0.2050, MAP@10=0.0792, product=0.01624262996031745898140030703871161676943302, time=0.7796s\n",
      "Hybrid ALS+Content: Recall@10=0.0145, MAP@10=0.0084, product=0.00012166478174603175173035946032840115549334, time=2.4976s\n",
      "CVAE              : Recall@10=0.2550, MAP@10=0.1001, product=0.02552620833333333824621824703626771224662662, time=2.2941s\n",
      "\n",
      "=== ALL MODELS (WITH TIME) ===\n",
      "                model  Recall@10    MAP@10  Score_product    Time_s\n",
      "0          Popularity     0.1215  0.050592       0.006147  0.773442\n",
      "1            Item-kNN     0.6930  0.365411       0.253230  0.781160\n",
      "2                 ALS     0.3605  0.202511       0.073005  1.126696\n",
      "3            LightGCN     0.2050  0.079232       0.016243  0.779634\n",
      "4  Hybrid ALS+Content     0.0145  0.008391       0.000122  2.497577\n",
      "5                CVAE     0.2550  0.100103       0.025526  2.294066\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Helper: time recall@k + MAP@k for a given recommender\n",
    "def timed_eval(model_name, recommender_fn, k=10, n_users_eval=2000):\n",
    "    start = time.perf_counter()\n",
    "    rec = recall_at_k(recommender_fn, train_mat, test_mat,\n",
    "                      k=k, n_users_eval=n_users_eval)\n",
    "    m   = map_at_k(recommender_fn,    train_mat, test_mat,\n",
    "                   k=k, n_users_eval=n_users_eval)\n",
    "    elapsed = time.perf_counter() - start\n",
    "    score_prod = rec * m\n",
    "    print(f\"{model_name:18s}: \"\n",
    "          f\"Recall@{k}={rec:.4f}, \"\n",
    "          f\"MAP@{k}={m:.4f}, \"\n",
    "          f\"product={score_prod:.44f}, \"\n",
    "          f\"time={elapsed:.4f}s\")\n",
    "    return rec, m, elapsed\n",
    "\n",
    "print(\"\\n=== TIMED EVALUATION FOR ALL MODELS ===\")\n",
    "\n",
    "# 1) Popularity\n",
    "pop_rec_t, pop_map_t, pop_time = timed_eval(\"Popularity\", pop_recommender)\n",
    "\n",
    "# 2) Item-kNN\n",
    "knn_rec_t, knn_map_t, knn_time = timed_eval(\"Item-kNN\", itemknn_recommender)\n",
    "\n",
    "# 3) ALS\n",
    "als_rec_t, als_map_t, als_time = timed_eval(\"ALS\", als_recommender)\n",
    "\n",
    "# 4) LightGCN\n",
    "lg_rec_t, lg_map_t, lg_time = timed_eval(\"LightGCN\", lightgcn_recommender)\n",
    "\n",
    "# 5) Hybrid ALS + Content\n",
    "hyb_rec_t, hyb_map_t, hyb_time = timed_eval(\"Hybrid ALS+Content\", hybrid_recommender)\n",
    "\n",
    "# 6) CVAE\n",
    "cvae_rec_t, cvae_map_t, cvae_time = timed_eval(\"CVAE\", cvae_recommender)\n",
    "\n",
    "# Build a full summary table\n",
    "timed_summary = pd.DataFrame({\n",
    "    \"model\": [\n",
    "        \"Popularity\",\n",
    "        \"Item-kNN\",\n",
    "        \"ALS\",\n",
    "        \"LightGCN\",\n",
    "        \"Hybrid ALS+Content\",\n",
    "        \"CVAE\"\n",
    "    ],\n",
    "    \"Recall@10\": [\n",
    "        pop_rec_t,\n",
    "        knn_rec_t,\n",
    "        als_rec_t,\n",
    "        lg_rec_t,\n",
    "        hyb_rec_t,\n",
    "        cvae_rec_t\n",
    "    ],\n",
    "    \"MAP@10\": [\n",
    "        pop_map_t,\n",
    "        knn_map_t,\n",
    "        als_map_t,\n",
    "        lg_map_t,\n",
    "        hyb_map_t,\n",
    "        cvae_map_t\n",
    "    ],\n",
    "    \"Score_product\": [\n",
    "        pop_rec_t * pop_map_t,\n",
    "        knn_rec_t * knn_map_t,\n",
    "        als_rec_t * als_map_t,\n",
    "        lg_rec_t * lg_map_t,\n",
    "        hyb_rec_t * hyb_map_t,\n",
    "        cvae_rec_t * cvae_map_t\n",
    "    ],\n",
    "    \"Time_s\": [\n",
    "        pop_time,\n",
    "        knn_time,\n",
    "        als_time,\n",
    "        lg_time,\n",
    "        hyb_time,\n",
    "        cvae_time\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n=== ALL MODELS (WITH TIME) ===\")\n",
    "print(timed_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:48:26.600034Z",
     "iopub.status.busy": "2025-11-14T14:48:26.599685Z",
     "iopub.status.idle": "2025-11-14T14:48:26.758454Z",
     "shell.execute_reply": "2025-11-14T14:48:26.757162Z",
     "shell.execute_reply.started": "2025-11-14T14:48:26.600003Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All classical models & artifacts saved in ./models/\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import os\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# 1) Save encoders\n",
    "with open(\"models/user_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(user_encoder, f)\n",
    "\n",
    "with open(\"models/item_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_encoder, f)\n",
    "\n",
    "# 2) Save item catalog (for showing product info on website)\n",
    "items_catalog.to_parquet(\"models/items_catalog.parquet\")\n",
    "\n",
    "# 3) Save interaction matrices (optional but useful)\n",
    "sp.save_npz(\"models/train_mat.npz\", train_mat)\n",
    "sp.save_npz(\"models/test_mat.npz\",  test_mat)\n",
    "\n",
    "# 4) Save Popularity model (just item_popularity and sorted indices)\n",
    "np.save(\"models/item_popularity.npy\", item_popularity)\n",
    "np.save(\"models/popular_items_sorted.npy\", popular_items_sorted)\n",
    "\n",
    "# 5) Save Item-kNN similarity matrix\n",
    "np.save(\"models/item_sim_dense.npy\", item_sim_dense)\n",
    "\n",
    "# 6) Save ALS model (entire object via pickle)\n",
    "with open(\"models/als_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(als_model, f)\n",
    "\n",
    "# 7) Save Hybrid content components (TF-IDF vectorizer + X_tfidf)\n",
    "with open(\"models/tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "sp.save_npz(\"models/X_tfidf.npz\", X_tfidf)\n",
    "\n",
    "print(\"‚úÖ All classical models & artifacts saved in ./models/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:48:26.759871Z",
     "iopub.status.busy": "2025-11-14T14:48:26.759514Z",
     "iopub.status.idle": "2025-11-14T14:48:26.876661Z",
     "shell.execute_reply": "2025-11-14T14:48:26.875678Z",
     "shell.execute_reply.started": "2025-11-14T14:48:26.759846Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# serve_recommender.py\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# ---- Load artifacts ----\n",
    "with open(\"models/user_encoder.pkl\", \"rb\") as f:\n",
    "    user_encoder = pickle.load(f)\n",
    "\n",
    "with open(\"models/item_encoder.pkl\", \"rb\") as f:\n",
    "    item_encoder = pickle.load(f)\n",
    "\n",
    "items_catalog = pd.read_parquet(\"models/items_catalog.parquet\")\n",
    "\n",
    "train_mat = sp.load_npz(\"models/train_mat.npz\")\n",
    "\n",
    "item_popularity      = np.load(\"models/item_popularity.npy\")\n",
    "popular_items_sorted = np.load(\"models/popular_items_sorted.npy\")\n",
    "item_sim_dense       = np.load(\"models/item_sim_dense.npy\")\n",
    "\n",
    "with open(\"models/als_model.pkl\", \"rb\") as f:\n",
    "    als_model = pickle.load(f)\n",
    "\n",
    "with open(\"models/tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "X_tfidf = sp.load_npz(\"models/X_tfidf.npz\")\n",
    "n_users, n_items = train_mat.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:48:26.877944Z",
     "iopub.status.busy": "2025-11-14T14:48:26.877611Z",
     "iopub.status.idle": "2025-11-14T14:48:26.889128Z",
     "shell.execute_reply": "2025-11-14T14:48:26.887642Z",
     "shell.execute_reply.started": "2025-11-14T14:48:26.877914Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def pop_recommender(user_id, N=10):\n",
    "    known_items = set(train_mat[user_id].indices)\n",
    "    rec = [i for i in popular_items_sorted if i not in known_items]\n",
    "    return np.array(rec[:N], dtype=int)\n",
    "\n",
    "def itemknn_recommender(user_id, N=10):\n",
    "    user_row = train_mat[user_id]\n",
    "    user_items = user_row.indices\n",
    "    if len(user_items) == 0:\n",
    "        return pop_recommender(user_id, N)\n",
    "\n",
    "    user_weights_full = np.asarray(user_row.toarray()).ravel()\n",
    "    user_weights = user_weights_full[user_items]\n",
    "\n",
    "    scores = item_sim_dense[:, user_items] @ user_weights\n",
    "    scores[user_items] = -np.inf\n",
    "\n",
    "    rec_items = np.argsort(-scores)[:N]\n",
    "    return rec_items\n",
    "\n",
    "def als_recommender(user_id, N=10):\n",
    "    user_items = train_mat[user_id]\n",
    "    item_ids, scores = als_model.recommend(\n",
    "        userid=user_id,\n",
    "        user_items=user_items,\n",
    "        N=N,\n",
    "        filter_already_liked_items=True\n",
    "    )\n",
    "    return item_ids\n",
    "\n",
    "# Hybrid: ALS + content\n",
    "def hybrid_recommender(user_id, alpha=0.6, N=10):\n",
    "    user_row = train_mat[user_id]\n",
    "    user_items = user_row.indices\n",
    "    if len(user_items) == 0:\n",
    "        return pop_recommender(user_id, N)\n",
    "\n",
    "    # CF scores\n",
    "    cf_scores = als_model.item_factors @ als_model.user_factors[user_id]\n",
    "\n",
    "    # Content scores from TF-IDF profile\n",
    "    weights_full = np.asarray(user_row.toarray()).ravel()\n",
    "    w = weights_full[user_items]\n",
    "    if w.sum() == 0:\n",
    "        w = np.ones_like(w)\n",
    "\n",
    "    profile_vec = (X_tfidf[user_items].T @ w).ravel()\n",
    "    norm = np.linalg.norm(profile_vec)\n",
    "    if norm > 0:\n",
    "        profile_vec = profile_vec / norm\n",
    "\n",
    "    cb_scores = (X_tfidf @ profile_vec).ravel()\n",
    "\n",
    "    scores = alpha * cf_scores + (1 - alpha) * cb_scores\n",
    "    scores[user_items] = -np.inf\n",
    "\n",
    "    rec_items = np.argsort(-scores)[:N]\n",
    "    return rec_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:48:26.890699Z",
     "iopub.status.busy": "2025-11-14T14:48:26.890366Z",
     "iopub.status.idle": "2025-11-14T14:48:26.919322Z",
     "shell.execute_reply": "2025-11-14T14:48:26.918032Z",
     "shell.execute_reply.started": "2025-11-14T14:48:26.890666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MODEL_MAP = {\n",
    "    \"popularity\": pop_recommender,\n",
    "    \"itemknn\":    itemknn_recommender,\n",
    "    \"als\":        als_recommender,\n",
    "    \"hybrid\":     hybrid_recommender,\n",
    "    \"lightgcn\": lightgcn_recommender,\n",
    "    \"cvae\":     cvae_recommender,\n",
    "}\n",
    "\n",
    "def recommend_for_customer(customer_id: int, model_name: str = \"hybrid\", N: int = 10):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      customer_id: the raw Tails customer_id from your database (int or str)\n",
    "      model_name: one of 'popularity', 'itemknn', 'als', 'hybrid', ...\n",
    "      N: number of items to recommend\n",
    "\n",
    "    Output:\n",
    "      List[dict] ‚Äî each dict is one recommended item:\n",
    "      {\n",
    "         \"item_key\": \"tails_superpremium|150g|mature|small\",\n",
    "         \"source\": \"tails\",\n",
    "         \"category\": \"superpremium\",\n",
    "         \"size\": \"150g\",\n",
    "         \"name\": \"...\",\n",
    "         \"brand\": \"...\",\n",
    "         \"rank\": 0\n",
    "      }\n",
    "    \"\"\"\n",
    "    raw_user_key = f\"cust_{customer_id}\"\n",
    "\n",
    "    # Cold-start: user not seen in training\n",
    "    if raw_user_key not in user_encoder.classes_:\n",
    "        # You can return top-N popular items directly here\n",
    "        uid = None\n",
    "        rec_ids = popular_items_sorted[:N]\n",
    "    else:\n",
    "        uid = user_encoder.transform([raw_user_key])[0]\n",
    "\n",
    "        if model_name not in MODEL_MAP:\n",
    "            model_name = \"hybrid\"  # default\n",
    "\n",
    "        rec_fn = MODEL_MAP[model_name]\n",
    "        # Some recommenders accept only (user_id, N), hybrid takes (user_id, N) via default alpha\n",
    "        rec_ids = rec_fn(uid, N)\n",
    "\n",
    "    # Map item_ids back to item_keys\n",
    "    rec_ids = np.array(rec_ids, dtype=int)\n",
    "    rec_keys = item_encoder.inverse_transform(rec_ids)\n",
    "\n",
    "    # Enrich with catalog info\n",
    "    rec_df = items_catalog[items_catalog[\"item_key\"].isin(rec_keys)].copy()\n",
    "    rank_map = {k: i for i, k in enumerate(rec_keys)}\n",
    "    rec_df[\"rank\"] = rec_df[\"item_key\"].map(rank_map)\n",
    "\n",
    "    rec_df = rec_df.sort_values(\"rank\")\n",
    "\n",
    "    # Choose what fields you want your website to see:\n",
    "    return rec_df[[\n",
    "        \"item_key\", \"source\", \"category\", \"size\", \"name\", \"brand\", \"rank\"\n",
    "    ]].to_dict(orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:48:26.920865Z",
     "iopub.status.busy": "2025-11-14T14:48:26.920538Z",
     "iopub.status.idle": "2025-11-14T14:48:26.954277Z",
     "shell.execute_reply": "2025-11-14T14:48:26.953156Z",
     "shell.execute_reply.started": "2025-11-14T14:48:26.920831Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item_key': 'tails_mid|150g|senior|medium', 'source': 'tails', 'category': 'mid', 'size': '150g', 'name': None, 'brand': None, 'rank': 0}\n",
      "{'item_key': 'tails_mid|300g|mature|large', 'source': 'tails', 'category': 'mid', 'size': '300g', 'name': None, 'brand': None, 'rank': 1}\n",
      "{'item_key': 'tails_mid|300g|mature|small', 'source': 'tails', 'category': 'mid', 'size': '300g', 'name': None, 'brand': None, 'rank': 2}\n",
      "{'item_key': 'tails_premium|150g|half_maturity|medium', 'source': 'tails', 'category': 'premium', 'size': '150g', 'name': None, 'brand': None, 'rank': 3}\n",
      "{'item_key': 'tails_mid|150g|weaning|large', 'source': 'tails', 'category': 'mid', 'size': '150g', 'name': None, 'brand': None, 'rank': 4}\n",
      "{'item_key': 'tails_mid|300g|senior|medium', 'source': 'tails', 'category': 'mid', 'size': '300g', 'name': None, 'brand': None, 'rank': 5}\n",
      "{'item_key': 'tails_premium|150g|senior|small', 'source': 'tails', 'category': 'premium', 'size': '150g', 'name': None, 'brand': None, 'rank': 6}\n",
      "{'item_key': 'tails_mid|300g|senior|giant', 'source': 'tails', 'category': 'mid', 'size': '300g', 'name': None, 'brand': None, 'rank': 7}\n",
      "{'item_key': 'tails_mid|300g|weaning|large', 'source': 'tails', 'category': 'mid', 'size': '300g', 'name': None, 'brand': None, 'rank': 8}\n",
      "{'item_key': 'ali_125', 'source': 'aliexpress', 'category': 'AliExpressPetSupplies', 'size': None, 'name': 'Premium Felt Cat Bed Cave - Handmade 100% Merino Wool Bed for Cats and Kittens', 'brand': None, 'rank': 9}\n"
     ]
    }
   ],
   "source": [
    "# Example local test:\n",
    "if __name__ == \"__main__\":\n",
    "    example_customer = 10574848487411271014\n",
    "    recs = recommend_for_customer(example_customer, model_name=\"hybrid\", N=10)\n",
    "    for r in recs:\n",
    "        print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:48:26.955785Z",
     "iopub.status.busy": "2025-11-14T14:48:26.955452Z",
     "iopub.status.idle": "2025-11-14T14:48:26.988402Z",
     "shell.execute_reply": "2025-11-14T14:48:26.987328Z",
     "shell.execute_reply.started": "2025-11-14T14:48:26.955757Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SESSION-BASED RECS (example) ===\n",
      "{'item_key': 'tails_superpremium|150g|senior|small', 'source': 'tails', 'category': 'superpremium', 'size': '150g', 'name': None, 'brand': None, 'rank': 0}\n",
      "{'item_key': 'tails_superpremium|300g|half_maturity|small', 'source': 'tails', 'category': 'superpremium', 'size': '300g', 'name': None, 'brand': None, 'rank': 1}\n",
      "{'item_key': 'tails_mid|300g|senior|large', 'source': 'tails', 'category': 'mid', 'size': '300g', 'name': None, 'brand': None, 'rank': 2}\n",
      "{'item_key': 'tails_superpremium|none|mature|small', 'source': 'tails', 'category': 'superpremium', 'size': 'none', 'name': None, 'brand': None, 'rank': 3}\n",
      "{'item_key': 'tails_superpremium|none|half_maturity|small', 'source': 'tails', 'category': 'superpremium', 'size': 'none', 'name': None, 'brand': None, 'rank': 4}\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SESSION-BASED (CLICK / CART / PURCHASE) RECOMMENDER\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "\n",
    "# Event weights: tune these as you like\n",
    "ACTION_WEIGHTS = {\n",
    "    \"view\":        1.0,   # or \"click\"\n",
    "    \"click\":       1.0,\n",
    "    \"add_to_cart\": 2.0,\n",
    "    \"purchase\":    3.0,\n",
    "}\n",
    "\n",
    "def _item_ids_from_keys(item_keys):\n",
    "    \"\"\"\n",
    "    Map list of item_key strings -> numpy array of item_ids.\n",
    "    Unknown keys are silently dropped.\n",
    "    \"\"\"\n",
    "    valid_keys = [k for k in item_keys if k in item_encoder.classes_]\n",
    "    if not valid_keys:\n",
    "        return np.array([], dtype=int)\n",
    "    return item_encoder.transform(valid_keys)\n",
    "\n",
    "def session_itemknn_scores(session_events):\n",
    "    \"\"\"\n",
    "    session_events: list of dicts like\n",
    "       {\"item_key\": \"...\", \"event_type\": \"click\" | \"add_to_cart\" | \"purchase\"}\n",
    "\n",
    "    Returns:\n",
    "        scores : np.array shape (n_items,) ‚Äî score for each item_id\n",
    "        seen_ids : list of item_ids present in session\n",
    "    \"\"\"\n",
    "    scores = np.zeros(item_sim_dense.shape[0], dtype=float)\n",
    "    seen_ids = []\n",
    "\n",
    "    for ev in session_events:\n",
    "        key = ev.get(\"item_key\")\n",
    "        et  = ev.get(\"event_type\", \"click\")\n",
    "        w   = ACTION_WEIGHTS.get(et, 1.0)\n",
    "\n",
    "        if key not in item_encoder.classes_:\n",
    "            continue\n",
    "\n",
    "        iid = item_encoder.transform([key])[0]\n",
    "        seen_ids.append(iid)\n",
    "\n",
    "        # Add similarity vector for this item, weighted by action type\n",
    "        scores += w * item_sim_dense[:, iid]\n",
    "\n",
    "    # Cold-start session: no valid items ‚Üí fallback to popularity\n",
    "    if not seen_ids:\n",
    "        scores = np.zeros(item_sim_dense.shape[0], dtype=float)\n",
    "        # simple decreasing scores by popularity ranking\n",
    "        scores[popular_items_sorted] = np.linspace(1.0, 0.0, len(popular_items_sorted))\n",
    "        return scores, []\n",
    "\n",
    "    # Don't recommend items already present in session\n",
    "    scores[seen_ids] = -np.inf\n",
    "    return scores, seen_ids\n",
    "\n",
    "def recommend_from_session(session_events, N=10):\n",
    "    \"\"\"\n",
    "    High-level API for your website: given current session actions, recommend items.\n",
    "\n",
    "    session_events example:\n",
    "    session_events = [\n",
    "        {\"item_key\": \"tails_superpremium|150g|mature|small\", \"event_type\": \"view\"},\n",
    "        {\"item_key\": \"tails_superpremium|300g|mature|small\", \"event_type\": \"add_to_cart\"},\n",
    "        {\"item_key\": \"amz_B00ABCXYZ\", \"event_type\": \"purchase\"},\n",
    "    ]\n",
    "    \"\"\"\n",
    "    scores, _ = session_itemknn_scores(session_events)\n",
    "    rec_ids = np.argsort(-scores)[:N]          # top-N item_ids\n",
    "    rec_keys = item_encoder.inverse_transform(rec_ids)\n",
    "\n",
    "    rec_df = items_catalog[items_catalog[\"item_key\"].isin(rec_keys)].copy()\n",
    "    rank_map = {k: i for i, k in enumerate(rec_keys)}\n",
    "    rec_df[\"rank\"] = rec_df[\"item_key\"].map(rank_map)\n",
    "    rec_df = rec_df.sort_values(\"rank\").reset_index(drop=True)\n",
    "\n",
    "    return rec_df[[\n",
    "        \"item_key\", \"source\", \"category\", \"size\", \"name\", \"brand\", \"rank\"\n",
    "    ]].to_dict(orient=\"records\")\n",
    "\n",
    "# ----------------- quick demo -----------------\n",
    "# Example session:\n",
    "example_session = [\n",
    "    {\"item_key\": \"tails_superpremium|150g|mature|small\", \"event_type\": \"view\"},\n",
    "    {\"item_key\": \"tails_superpremium|300g|mature|small\", \"event_type\": \"add_to_cart\"},\n",
    "]\n",
    "\n",
    "print(\"\\n=== SESSION-BASED RECS (example) ===\")\n",
    "for rec in recommend_from_session(example_session, N=5):\n",
    "    print(rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:48:26.989823Z",
     "iopub.status.busy": "2025-11-14T14:48:26.989580Z",
     "iopub.status.idle": "2025-11-14T14:48:27.048332Z",
     "shell.execute_reply": "2025-11-14T14:48:27.047307Z",
     "shell.execute_reply.started": "2025-11-14T14:48:26.989804Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEMO: SESSION-BASED RECS (from one clicked item) ===\n",
      "{'item_key': 'tails_superpremium|150g|weaning|small', 'source': 'tails', 'category': 'superpremium', 'size': '150g', 'name': None, 'brand': None, 'rank': 0}\n",
      "{'item_key': 'tails_superpremium|150g|weaning|medium', 'source': 'tails', 'category': 'superpremium', 'size': '150g', 'name': None, 'brand': None, 'rank': 1}\n",
      "{'item_key': 'tails_superpremium|150g|half_maturity|giant', 'source': 'tails', 'category': 'superpremium', 'size': '150g', 'name': None, 'brand': None, 'rank': 2}\n",
      "{'item_key': 'tails_superpremium|150g|half_maturity|large', 'source': 'tails', 'category': 'superpremium', 'size': '150g', 'name': None, 'brand': None, 'rank': 3}\n",
      "{'item_key': 'tails_superpremium|150g|half_maturity|small', 'source': 'tails', 'category': 'superpremium', 'size': '150g', 'name': None, 'brand': None, 'rank': 4}\n",
      "\n",
      "=== DEMO: TEXT-BASED RECS (single description) ===\n",
      "{'item_key': 'ali_125', 'source': 'aliexpress', 'category': 'AliExpressPetSupplies', 'size': None, 'name': 'Premium Felt Cat Bed Cave - Handmade 100% Merino Wool Bed for Cats and Kittens', 'brand': None, 'rank': 0}\n",
      "{'item_key': 'ali_482', 'source': 'aliexpress', 'category': 'AliExpressPetSupplies', 'size': None, 'name': 'Premium Felt Cat Bed Cave - Handmade 100% Merino Wool Bed for Cats and Kittens', 'brand': None, 'rank': 1}\n",
      "{'item_key': 'amz_B07PK3QFT4', 'source': 'amazon', 'category': 'Pet Supplies | Cats | Beds & Furniture | Beds', 'size': None, 'name': 'SRI Soft Cat Premium Bed (Blue)', 'brand': 'Visit the SRI Store', 'rank': 2}\n",
      "{'item_key': 'chewy_4cdec718-dc72-57dc-9098-379a9dbb3dc4', 'source': 'chewy', 'category': 'Dog>Cleaning & Potty>Poop Bags & Scoopers>Poop Bags', 'size': None, 'name': 'Doggy Do Good Certified Compostable Premium Dog & Cat Waste Bags, Small Handle Bags - On Rolls + Dispenser, 60 count', 'brand': 'Doggy Do Good', 'rank': 3}\n",
      "{'item_key': 'ali_303', 'source': 'aliexpress', 'category': 'AliExpressPetSupplies', 'size': None, 'name': '39.6‚Äù Dog Gate for Stairs & Doorways, 30\" Tall Baby Gate Pressure Mount Pet Gates, Easy Step Auto Close Both Sides Walk Thru', 'brand': None, 'rank': 4}\n",
      "\n",
      "=== DEMO: TEXT-BASED RECS (two descriptions combined) ===\n",
      "{'item_key': 'chewy_4cdec718-dc72-57dc-9098-379a9dbb3dc4', 'source': 'chewy', 'category': 'Dog>Cleaning & Potty>Poop Bags & Scoopers>Poop Bags', 'size': None, 'name': 'Doggy Do Good Certified Compostable Premium Dog & Cat Waste Bags, Small Handle Bags - On Rolls + Dispenser, 60 count', 'brand': 'Doggy Do Good', 'rank': 0}\n",
      "{'item_key': 'ali_303', 'source': 'aliexpress', 'category': 'AliExpressPetSupplies', 'size': None, 'name': '39.6‚Äù Dog Gate for Stairs & Doorways, 30\" Tall Baby Gate Pressure Mount Pet Gates, Easy Step Auto Close Both Sides Walk Thru', 'brand': None, 'rank': 1}\n",
      "{'item_key': 'ali_125', 'source': 'aliexpress', 'category': 'AliExpressPetSupplies', 'size': None, 'name': 'Premium Felt Cat Bed Cave - Handmade 100% Merino Wool Bed for Cats and Kittens', 'brand': None, 'rank': 2}\n",
      "{'item_key': 'tails_premium|none|weaning|medium', 'source': 'tails', 'category': 'premium', 'size': 'none', 'name': None, 'brand': None, 'rank': 3}\n",
      "{'item_key': 'tails_premium|none|weaning|small', 'source': 'tails', 'category': 'premium', 'size': 'none', 'name': None, 'brand': None, 'rank': 4}\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2.2 SESSION-BASED & TEXT-BASED RECOMMENDERS\n",
    "#    - Session / click-based recs from item(s)\n",
    "#    - Text ‚Üí items (single description)\n",
    "#    - Two descriptions combined (profile + intent)\n",
    "# ============================================================\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize as skl_normalize\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# A) Build item text features (for content similarity)\n",
    "# ------------------------------------------------------------\n",
    "# Use only items that appear in the user‚Äìitem matrix (item_id >= 0)\n",
    "known_items = items_catalog[items_catalog[\"item_id\"] >= 0].copy()\n",
    "known_items = known_items.sort_values(\"item_id\")\n",
    "known_ids   = known_items[\"item_id\"].to_numpy()\n",
    "\n",
    "# Build text for each item (source + category + size + pet_type + name + brand)\n",
    "def make_item_text(row):\n",
    "    parts = [\n",
    "        str(row.get(\"source\", \"\")),\n",
    "        str(row.get(\"category\", \"\")),\n",
    "        str(row.get(\"size\", \"\")),\n",
    "        str(row.get(\"pet_type\", \"\")),\n",
    "        str(row.get(\"name\", \"\")),\n",
    "        str(row.get(\"brand\", \"\")),\n",
    "    ]\n",
    "    parts = [p for p in parts if p and p != \"nan\"]\n",
    "    return \" \".join(parts)\n",
    "\n",
    "known_items[\"text\"] = known_items.apply(make_item_text, axis=1).fillna(\"\")\n",
    "\n",
    "# TF‚ÄìIDF over item texts\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf    = vectorizer.fit_transform(known_items[\"text\"])\n",
    "X_tfidf    = skl_normalize(X_tfidf)        # (n_known_items, d), L2-normalized\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# B) Small helper: from query vector ‚Üí scores over known items\n",
    "# ------------------------------------------------------------\n",
    "def _scores_from_query_vec(q_vec):\n",
    "    \"\"\"\n",
    "    q_vec: 1√ód sparse vector (already normalized)\n",
    "    Returns a dense 1D array of similarity scores for each known item.\n",
    "    \"\"\"\n",
    "    sims   = X_tfidf @ q_vec.T        # csr_matrix (n_known_items √ó 1)\n",
    "    scores = np.asarray(sims.toarray()).ravel()\n",
    "    return scores\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# C) SESSION / CLICK-BASED RECOMMENDER\n",
    "#    \"If the user just clicked item X, recommend similar items\"\n",
    "# ------------------------------------------------------------\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize as skl_normalize\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# ... (known_items, vectorizer, X_tfidf, _scores_from_query_vec as before)\n",
    "\n",
    "def session_recommender_from_clicks(clicked_item_keys, N=10):\n",
    "    \"\"\"\n",
    "    clicked_item_keys: string or list of item_key(s) that user just interacted with\n",
    "    Returns: list of dicts with recommended items.\n",
    "    \"\"\"\n",
    "    # Accept single string or list\n",
    "    if isinstance(clicked_item_keys, str):\n",
    "        clicked_item_keys = [clicked_item_keys]\n",
    "\n",
    "    # Map item_key -> item_id, keep only items that exist in matrix\n",
    "    valid_item_ids = []\n",
    "    for k in clicked_item_keys:\n",
    "        if k in item_encoder.classes_:\n",
    "            iid = item_encoder.transform([k])[0]\n",
    "            valid_item_ids.append(iid)\n",
    "\n",
    "    if not valid_item_ids:\n",
    "        # Fall back to popularity if we cannot map any clicked items\n",
    "        print(\"[session] No valid clicked items found, fallback to popularity.\")\n",
    "        rec_items = pop_recommender(0, N)\n",
    "        rec_keys  = item_encoder.inverse_transform(rec_items)\n",
    "    else:\n",
    "        # Use the TF‚ÄìIDF content similarity of these clicked items\n",
    "        rows = [iid for iid in valid_item_ids if iid < X_tfidf.shape[0]]\n",
    "        if not rows:\n",
    "            print(\"[session] Item IDs not present in known_items, fallback to popularity.\")\n",
    "            rec_items = pop_recommender(0, N)\n",
    "            rec_keys  = item_encoder.inverse_transform(rec_items)\n",
    "        else:\n",
    "            # ---- FIXED PART ----\n",
    "            # sum() returns a numpy.matrix; turn it back into a CSR sparse matrix\n",
    "            q_vec = X_tfidf[rows].sum(axis=0)          # 1√ód numpy.matrix\n",
    "            q_vec = sp.csr_matrix(q_vec)               # ‚Üí 1√ód csr_matrix\n",
    "            q_vec = skl_normalize(q_vec, norm=\"l2\")    # L2 norm = 1\n",
    "            # --------------------\n",
    "\n",
    "            scores = _scores_from_query_vec(q_vec)\n",
    "\n",
    "            # Do not recommend clicked items themselves\n",
    "            for iid in valid_item_ids:\n",
    "                if iid < len(scores):\n",
    "                    scores[iid] = -np.inf\n",
    "\n",
    "            top_idx      = np.argsort(-scores)[:N]\n",
    "            top_item_ids = known_items.iloc[top_idx][\"item_id\"].to_numpy()\n",
    "            rec_keys     = item_encoder.inverse_transform(top_item_ids)\n",
    "\n",
    "    rec_df   = items_catalog[items_catalog[\"item_key\"].isin(rec_keys)].copy()\n",
    "    rank_map = {k: i for i, k in enumerate(rec_keys)}\n",
    "    rec_df[\"rank\"] = rec_df[\"item_key\"].map(rank_map)\n",
    "    rec_df = rec_df.sort_values(\"rank\").reset_index(drop=True)\n",
    "\n",
    "    return rec_df[[\"item_key\", \"source\", \"category\", \"size\", \"name\", \"brand\", \"rank\"]] \\\n",
    "        .to_dict(orient=\"records\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# D) TEXT-BASED RECOMMENDER (single description)\n",
    "# ------------------------------------------------------------\n",
    "def recommend_from_text(description, N=10):\n",
    "    \"\"\"\n",
    "    Recommend items purely from a user text description.\n",
    "\n",
    "    Example:\n",
    "        recs = recommend_from_text(\n",
    "            \"dry food for small senior dog, sensitive stomach, grain free\",\n",
    "            N=10\n",
    "        )\n",
    "    \"\"\"\n",
    "    q = vectorizer.transform([description])\n",
    "    q = skl_normalize(q)   # 1√ód\n",
    "\n",
    "    scores       = _scores_from_query_vec(q)\n",
    "    top_idx      = np.argsort(-scores)[:N]\n",
    "    top_item_ids = known_items.iloc[top_idx][\"item_id\"].to_numpy()\n",
    "\n",
    "    rec_keys = item_encoder.inverse_transform(top_item_ids)\n",
    "    rec_df   = items_catalog[items_catalog[\"item_key\"].isin(rec_keys)].copy()\n",
    "    rank_map = {k: i for i, k in enumerate(rec_keys)}\n",
    "    rec_df[\"rank\"] = rec_df[\"item_key\"].map(rank_map)\n",
    "    rec_df = rec_df.sort_values(\"rank\").reset_index(drop=True)\n",
    "\n",
    "    return rec_df[[\"item_key\", \"source\", \"category\", \"size\", \"name\", \"brand\", \"rank\"]] \\\n",
    "        .to_dict(orient=\"records\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# E) TEXT-BASED RECOMMENDER (two descriptions combined)\n",
    "# ------------------------------------------------------------\n",
    "def recommend_from_two_texts(desc1, desc2, w1=0.5, w2=0.5, N=10):\n",
    "    \"\"\"\n",
    "    Combine two descriptions (e.g. 'long-term profile' + 'current need').\n",
    "\n",
    "    Example:\n",
    "        desc_profile = \"small senior dog, sensitive stomach\"\n",
    "        desc_intent  = \"wet food with chicken and rice\"\n",
    "        recs = recommend_from_two_texts(desc_profile, desc_intent, w1=0.7, w2=0.3, N=10)\n",
    "    \"\"\"\n",
    "    q1 = vectorizer.transform([desc1])\n",
    "    q2 = vectorizer.transform([desc2])\n",
    "\n",
    "    q1 = skl_normalize(q1)\n",
    "    q2 = skl_normalize(q2)\n",
    "\n",
    "    # Weighted sum of two queries, then normalize again\n",
    "    q_comb = w1 * q1 + w2 * q2\n",
    "    q_comb = skl_normalize(q_comb)\n",
    "\n",
    "    scores       = _scores_from_query_vec(q_comb)\n",
    "    top_idx      = np.argsort(-scores)[:N]\n",
    "    top_item_ids = known_items.iloc[top_idx][\"item_id\"].to_numpy()\n",
    "\n",
    "    rec_keys = item_encoder.inverse_transform(top_item_ids)\n",
    "    rec_df   = items_catalog[items_catalog[\"item_key\"].isin(rec_keys)].copy()\n",
    "    rank_map = {k: i for i, k in enumerate(rec_keys)}\n",
    "    rec_df[\"rank\"] = rec_df[\"item_key\"].map(rank_map)\n",
    "    rec_df = rec_df.sort_values(\"rank\").reset_index(drop=True)\n",
    "\n",
    "    return rec_df[[\"item_key\", \"source\", \"category\", \"size\", \"name\", \"brand\", \"rank\"]] \\\n",
    "        .to_dict(orient=\"records\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# F) QUICK DEMOS (you can comment these out in production)\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\n=== DEMO: SESSION-BASED RECS (from one clicked item) ===\")\n",
    "demo_clicked = \"tails_superpremium|150g|mature|small\"\n",
    "for rec in session_recommender_from_clicks(demo_clicked, N=5):\n",
    "    print(rec)\n",
    "\n",
    "print(\"\\n=== DEMO: TEXT-BASED RECS (single description) ===\")\n",
    "demo_desc = \"dry cat food for indoor adult cat, high protein, hairball control\"\n",
    "for rec in recommend_from_text(demo_desc, N=5):\n",
    "    print(rec)\n",
    "\n",
    "print(\"\\n=== DEMO: TEXT-BASED RECS (two descriptions combined) ===\")\n",
    "desc_profile = \"small senior dog, sensitive stomach\"\n",
    "desc_intent  = \"grain-free chicken dry food\"\n",
    "for rec in recommend_from_two_texts(desc_profile, desc_intent, w1=0.7, w2=0.3, N=5):\n",
    "    print(rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:48:27.049590Z",
     "iopub.status.busy": "2025-11-14T14:48:27.049337Z",
     "iopub.status.idle": "2025-11-14T14:48:27.100350Z",
     "shell.execute_reply": "2025-11-14T14:48:27.099483Z",
     "shell.execute_reply.started": "2025-11-14T14:48:27.049570Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model selected: Item-kNN\n",
      "model            Item-kNN\n",
      "Recall@10           0.693\n",
      "MAP@10           0.365411\n",
      "Score_product     0.25323\n",
      "Time_s            0.78116\n",
      "Name: 1, dtype: object\n",
      "Saved Item-kNN model and encoders to saved_models\n",
      "Saved TF-IDF content model (vectorizer + X_tfidf + known_items) to saved_models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1) Choose best model from timed_summary\n",
    "# -------------------------------------------------\n",
    "# timed_summary must already exist, e.g.:\n",
    "# timed_summary = pd.DataFrame({\n",
    "#     \"model\": [...],\n",
    "#     \"Recall@10\": [...],\n",
    "#     \"MAP@10\": [...],\n",
    "#     \"Score_product\": [...],\n",
    "#     \"Time_s\": [...]\n",
    "# })\n",
    "\n",
    "# Sort: highest Score_product, and if tie, prefer lower Time_s\n",
    "best_row = timed_summary.sort_values(\n",
    "    [\"Score_product\", \"Time_s\"],\n",
    "    ascending=[False, True]\n",
    ").iloc[0]\n",
    "\n",
    "best_name = best_row[\"model\"]\n",
    "print(\"Best model selected:\", best_name)\n",
    "print(best_row)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2) Prepare output folder + metadata\n",
    "# -------------------------------------------------\n",
    "MODEL_DIR = \"saved_models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "meta = {\n",
    "    \"best_model\": best_name,\n",
    "    \"timed_summary\": timed_summary.to_dict(orient=\"records\"),\n",
    "    \"n_users\": int(train_mat.shape[0]),\n",
    "    \"n_items\": int(train_mat.shape[1]),\n",
    "}\n",
    "\n",
    "with open(os.path.join(MODEL_DIR, \"metadata.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3) Export best CF model (ALS / Item-kNN / etc.)\n",
    "# -------------------------------------------------\n",
    "if best_name == \"ALS\":\n",
    "    # Save ALS model + encoders\n",
    "    joblib.dump(als_model,       os.path.join(MODEL_DIR, \"als_model.pkl\"))\n",
    "    joblib.dump(user_encoder,    os.path.join(MODEL_DIR, \"user_encoder.pkl\"))\n",
    "    joblib.dump(item_encoder,    os.path.join(MODEL_DIR, \"item_encoder.pkl\"))\n",
    "\n",
    "    # Save mapping item_id -> item_key + metadata\n",
    "    items_catalog.to_parquet(os.path.join(MODEL_DIR, \"items_catalog.parquet\"))\n",
    "\n",
    "    print(\"Saved ALS model and encoders to\", MODEL_DIR)\n",
    "\n",
    "elif best_name == \"Item-kNN\":\n",
    "    # Save similarity matrix and popularity vector\n",
    "    np.savez(\n",
    "        os.path.join(MODEL_DIR, \"itemknn_model.npz\"),\n",
    "        item_sim_dense=item_sim_dense,\n",
    "        item_popularity=item_popularity\n",
    "    )\n",
    "    joblib.dump(user_encoder, os.path.join(MODEL_DIR, \"user_encoder.pkl\"))\n",
    "    joblib.dump(item_encoder, os.path.join(MODEL_DIR, \"item_encoder.pkl\"))\n",
    "    items_catalog.to_parquet(os.path.join(MODEL_DIR, \"items_catalog.parquet\"))\n",
    "\n",
    "    print(\"Saved Item-kNN model and encoders to\", MODEL_DIR)\n",
    "\n",
    "elif best_name == \"Popularity\":\n",
    "    # Only need popularity + encoders\n",
    "    np.savez(\n",
    "        os.path.join(MODEL_DIR, \"pop_model.npz\"),\n",
    "        item_popularity=item_popularity\n",
    "    )\n",
    "    joblib.dump(user_encoder, os.path.join(MODEL_DIR, \"user_encoder.pkl\"))\n",
    "    joblib.dump(item_encoder, os.path.join(MODEL_DIR, \"item_encoder.pkl\"))\n",
    "    items_catalog.to_parquet(os.path.join(MODEL_DIR, \"items_catalog.parquet\"))\n",
    "\n",
    "    print(\"Saved Popularity model and encoders to\", MODEL_DIR)\n",
    "\n",
    "elif best_name == \"LightGCN\":\n",
    "    # Assuming you have a trained lightgcn_model (PyTorch)\n",
    "    joblib.dump(lightgcn_model,  os.path.join(MODEL_DIR, \"lightgcn_model.pkl\"))\n",
    "    joblib.dump(user_encoder,    os.path.join(MODEL_DIR, \"user_encoder.pkl\"))\n",
    "    joblib.dump(item_encoder,    os.path.join(MODEL_DIR, \"item_encoder.pkl\"))\n",
    "    items_catalog.to_parquet(os.path.join(MODEL_DIR, \"items_catalog.parquet\"))\n",
    "\n",
    "    print(\"Saved LightGCN model and encoders to\", MODEL_DIR)\n",
    "\n",
    "elif best_name == \"Hybrid ALS+Content\":\n",
    "    # Hybrid uses ALS + TF-IDF; save ALS + TF-IDF stuff\n",
    "    joblib.dump(als_model,       os.path.join(MODEL_DIR, \"als_model.pkl\"))\n",
    "    joblib.dump(user_encoder,    os.path.join(MODEL_DIR, \"user_encoder.pkl\"))\n",
    "    joblib.dump(item_encoder,    os.path.join(MODEL_DIR, \"item_encoder.pkl\"))\n",
    "    items_catalog.to_parquet(os.path.join(MODEL_DIR, \"items_catalog.parquet\"))\n",
    "\n",
    "    print(\"Saved Hybrid (ALS+Content) core (ALS + encoders) to\", MODEL_DIR)\n",
    "\n",
    "elif best_name == \"CVAE\":\n",
    "    # Assuming you have a trained CVAE model object\n",
    "    joblib.dump(cvae_model,      os.path.join(MODEL_DIR, \"cvae_model.pkl\"))\n",
    "    joblib.dump(user_encoder,    os.path.join(MODEL_DIR, \"user_encoder.pkl\"))\n",
    "    joblib.dump(item_encoder,    os.path.join(MODEL_DIR, \"item_encoder.pkl\"))\n",
    "    items_catalog.to_parquet(os.path.join(MODEL_DIR, \"items_catalog.parquet\"))\n",
    "\n",
    "    print(\"Saved CVAE model and encoders to\", MODEL_DIR)\n",
    "\n",
    "else:\n",
    "    print(\"Warning: best model name not recognized, only metadata exported.\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4) Export content / TF-IDF objects\n",
    "#    (for click-based & text-based recommendations)\n",
    "# -------------------------------------------------\n",
    "# These are useful even if the best CF model is ALS or kNN, because\n",
    "# you also want:\n",
    "#  - recommend_from_text(...)\n",
    "#  - session_recommender_from_clicks(...)\n",
    "# to work on your website.\n",
    "try:\n",
    "    from scipy.sparse import save_npz\n",
    "\n",
    "    # X_tfidf: (n_known_items, d)\n",
    "    save_npz(os.path.join(MODEL_DIR, \"X_tfidf.npz\"), X_tfidf)\n",
    "\n",
    "    # vectorizer: TfidfVectorizer\n",
    "    joblib.dump(vectorizer, os.path.join(MODEL_DIR, \"tfidf_vectorizer.pkl\"))\n",
    "\n",
    "    # known_items dataframe (id ‚Üî index in X_tfidf)\n",
    "    known_items.to_parquet(os.path.join(MODEL_DIR, \"known_items.parquet\"))\n",
    "\n",
    "    print(\"Saved TF-IDF content model (vectorizer + X_tfidf + known_items) to\", MODEL_DIR)\n",
    "\n",
    "except NameError:\n",
    "    print(\"TF-IDF objects (vectorizer / X_tfidf / known_items) not found in scope, skip saving.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:48:27.102143Z",
     "iopub.status.busy": "2025-11-14T14:48:27.101649Z",
     "iopub.status.idle": "2025-11-14T14:48:27.700847Z",
     "shell.execute_reply": "2025-11-14T14:48:27.699904Z",
     "shell.execute_reply.started": "2025-11-14T14:48:27.102110Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unified item-only catalog: (3557, 25)\n",
      "                              item_key source  \\\n",
      "0   tails_mid|150g|half_maturity|giant  tails   \n",
      "1   tails_mid|150g|half_maturity|large  tails   \n",
      "2  tails_mid|150g|half_maturity|medium  tails   \n",
      "3   tails_mid|150g|half_maturity|small  tails   \n",
      "4     tails_mid|150g|half_maturity|toy  tails   \n",
      "\n",
      "                            title_or_name  price  rating_raw  global_score  \\\n",
      "0   Tails mid 150g (half_maturity, giant)    NaN         NaN      0.156525   \n",
      "1   Tails mid 150g (half_maturity, large)    NaN         NaN      0.365662   \n",
      "2  Tails mid 150g (half_maturity, medium)    NaN         NaN      0.376695   \n",
      "3   Tails mid 150g (half_maturity, small)    NaN         NaN      0.470850   \n",
      "4     Tails mid 150g (half_maturity, toy)    NaN         NaN      0.364670   \n",
      "\n",
      "   final_score  \n",
      "0     0.385000  \n",
      "1     0.573337  \n",
      "2     0.583273  \n",
      "3     0.668064  \n",
      "4     0.572444  \n",
      "\n",
      "=== TOP 10 GLOBAL ITEMS (all sources) ===\n",
      "     item_key      source                                      title_or_name  \\\n",
      "0    ali_1367  aliexpress  Super Cat Bed Warm Pet House Kitten Cave Cushi...   \n",
      "1  store_4583       store                           Store Food (cat, medium)   \n",
      "2     ali_242  aliexpress  Pet Pets Supplies Canvas Garbage Bags Poop Bag...   \n",
      "3     ali_388  aliexpress  Dog Poop Bag Carrier Portable Pet Waste Bag Di...   \n",
      "4    ali_1151  aliexpress  Pet Dog Cat Necklace Adjustable Strap for Cat ...   \n",
      "5  store_4587       store                         Store Bedding (cat, small)   \n",
      "6  store_4620       store                   Store Bedding (dog, extra_small)   \n",
      "7    ali_1903  aliexpress  Wholesale 100Pcs Dog ID Tags Laser Engraving B...   \n",
      "8  store_4663       store                        Store Clothes (cat, medium)   \n",
      "9    ali_1792  aliexpress  Double Pet Bowls Dog Food Water Feeder Stainle...   \n",
      "\n",
      "    price  rating_raw  final_score  \n",
      "0     NaN         4.9     1.000000  \n",
      "1  1705.0        10.0     0.996338  \n",
      "2     NaN         4.9     0.993485  \n",
      "3     NaN         4.9     0.993126  \n",
      "4     NaN         4.7     0.992563  \n",
      "5  1022.0        10.0     0.989917  \n",
      "6  1039.0        10.0     0.988637  \n",
      "7     NaN         4.9     0.988041  \n",
      "8  3377.0        10.0     0.986881  \n",
      "9     NaN         4.6     0.986487  \n",
      "\n",
      "=== TOP 5 CHEAP STORE ITEMS FOR DOGS (price <= 10000) ===\n",
      "     item_key                         title_or_name   price  rating_raw  \\\n",
      "0  store_4620      Store Bedding (dog, extra_small)  1039.0        10.0   \n",
      "1  store_4700  Store Supplements (dog, extra_small)  3555.0        10.0   \n",
      "2  store_4540        Store Snack (dog, extra_small)   690.0        10.0   \n",
      "3  store_4564            Store Clothes (dog, large)  5194.0        10.0   \n",
      "4  store_4726           Store Medicine (dog, small)  3778.0        10.0   \n",
      "\n",
      "   sales  re_buy  final_score  \n",
      "0  199.0     1.0     0.988637  \n",
      "1  217.0     1.0     0.983481  \n",
      "2  177.0     1.0     0.980932  \n",
      "3  195.0     1.0     0.967037  \n",
      "4  171.0     1.0     0.963327  \n",
      "\n",
      "=== TOP 5 ALIEXPRESS ITEMS ===\n",
      "   item_key      source                                      title_or_name  \\\n",
      "0  ali_1367  aliexpress  Super Cat Bed Warm Pet House Kitten Cave Cushi...   \n",
      "1   ali_242  aliexpress  Pet Pets Supplies Canvas Garbage Bags Poop Bag...   \n",
      "2   ali_388  aliexpress  Dog Poop Bag Carrier Portable Pet Waste Bag Di...   \n",
      "3  ali_1151  aliexpress  Pet Dog Cat Necklace Adjustable Strap for Cat ...   \n",
      "4  ali_1903  aliexpress  Wholesale 100Pcs Dog ID Tags Laser Engraving B...   \n",
      "\n",
      "   rating_raw  trade_num   wished  quantity  final_score  \n",
      "0         4.9      700.0   3788.0   31362.0     1.000000  \n",
      "1         4.9      500.0   8684.0   14507.0     0.993485  \n",
      "2         4.9      900.0    878.0   39904.0     0.993126  \n",
      "3         4.7      485.0  11134.0  168008.0     0.992563  \n",
      "4         4.9      471.0   1255.0  683149.0     0.988041  \n",
      "\n",
      "=== TOP 5 TAILS ITEMS ===\n",
      "                                item_key  \\\n",
      "0   tails_superpremium|150g|mature|small   \n",
      "1     tails_superpremium|150g|mature|toy   \n",
      "2  tails_superpremium|150g|mature|medium   \n",
      "3  tails_superpremium|300g|mature|medium   \n",
      "4   tails_superpremium|300g|mature|small   \n",
      "\n",
      "                              title_or_name  n_orders  total_wet_trays  \\\n",
      "0   Tails superpremium 150g (mature, small)     537.0          33050.0   \n",
      "1     Tails superpremium 150g (mature, toy)     325.0          15243.0   \n",
      "2  Tails superpremium 150g (mature, medium)     248.0          16731.0   \n",
      "3  Tails superpremium 300g (mature, medium)     226.0          14977.0   \n",
      "4   Tails superpremium 300g (mature, small)     202.0          13302.0   \n",
      "\n",
      "      mean_kcal  mean_discount  final_score  \n",
      "0  13378.831052       0.158625     0.972280  \n",
      "1   8688.742784       0.185613     0.904075  \n",
      "2  19970.384726       0.162068     0.889505  \n",
      "3  26780.000839       0.137571     0.885520  \n",
      "4  17774.763497       0.105793     0.882077  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# CONFIG: base folder where you already copied the CSVs\n",
    "# -------------------------------------------------------------------\n",
    "BASE = Path(\"/kaggle/working/excel_csv\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Utility: safe numeric conversions & normalization\n",
    "# -------------------------------------------------------------------\n",
    "def to_numeric_series(s, regex_keep=r\"[0-9\\.,]+\"):\n",
    "    \"\"\"\n",
    "    Convert an object/string Series with currency / commas / text to float.\n",
    "    Example: '4,066.00' -> 4066.00, '25,17' (EU) -> 25.17, '5 sold' -> 5.0\n",
    "    \"\"\"\n",
    "    s = s.astype(str).str.extract(f\"({regex_keep})\", expand=False)\n",
    "    s = s.str.replace(\" \", \"\", regex=False)\n",
    "    # Replace thousand separators / decimal commas\n",
    "    s = s.str.replace(\".\", \"\", regex=False)\n",
    "    s = s.str.replace(\",\", \".\", regex=False)\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "\n",
    "def minmax_norm(x):\n",
    "    \"\"\"Min-max normalize a numeric Series to [0,1]. NaNs -> 0.\"\"\"\n",
    "    x = x.astype(float)\n",
    "    xmin, xmax = np.nanmin(x), np.nanmax(x)\n",
    "    if np.isfinite(xmin) and np.isfinite(xmax) and xmax > xmin:\n",
    "        out = (x - xmin) / (xmax - xmin)\n",
    "    else:\n",
    "        out = pd.Series(np.zeros(len(x)), index=x.index, dtype=float)\n",
    "    return out.fillna(0.0)\n",
    "\n",
    "\n",
    "def log1p_norm(x):\n",
    "    \"\"\"log1p then min-max normalize (useful for counts like sales / reviews).\"\"\"\n",
    "    return minmax_norm(np.log1p(x.astype(float)))\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 0) TAILS PET FOOD ORDERS ‚Üí aggregate to \"items\"\n",
    "#     Use pet_food_tier + wet_tray_size + pet_life_stage_at_order + pet_breed_size\n",
    "# -------------------------------------------------------------------\n",
    "def build_tails_items():\n",
    "    path = BASE / \"pet-food-customer-orders-online\" / \"pet_food_customer_orders.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Define a product-like key similar to your CF pipeline\n",
    "    df[\"wet_tray_size_clean\"] = df[\"wet_tray_size\"].fillna(\"none\").astype(str)\n",
    "    df[\"pet_life_stage_at_order\"] = df[\"pet_life_stage_at_order\"].fillna(\"unknown\").astype(str)\n",
    "    df[\"pet_breed_size\"] = df[\"pet_breed_size\"].fillna(\"unknown\").astype(str)\n",
    "    df[\"pet_food_tier\"] = df[\"pet_food_tier\"].fillna(\"unknown\").astype(str)\n",
    "\n",
    "    df[\"item_key\"] = (\n",
    "        \"tails_\" +\n",
    "        df[\"pet_food_tier\"].astype(str) + \"|\" +\n",
    "        df[\"wet_tray_size_clean\"].astype(str) + \"|\" +\n",
    "        df[\"pet_life_stage_at_order\"].astype(str) + \"|\" +\n",
    "        df[\"pet_breed_size\"].astype(str)\n",
    "    )\n",
    "    df[\"source\"] = \"tails\"\n",
    "\n",
    "    # Aggregate per item_key\n",
    "    grp = df.groupby(\"item_key\", as_index=False).agg(\n",
    "        n_orders=(\"customer_id\", \"nunique\"),        # number of distinct customers\n",
    "        n_rows=(\"customer_id\", \"size\"),            # total rows / orders\n",
    "        total_wet_trays=(\"wet_trays\", \"sum\"),\n",
    "        mean_kcal=(\"total_order_kcal\", \"mean\"),\n",
    "        mean_discount=(\"wet_food_discount_percent\", \"mean\")\n",
    "    )\n",
    "\n",
    "    # Normalize features\n",
    "    orders_norm = log1p_norm(grp[\"n_orders\"])\n",
    "    rows_norm = log1p_norm(grp[\"n_rows\"])\n",
    "    wet_trays_norm = log1p_norm(grp[\"total_wet_trays\"])\n",
    "    # lower discount is slightly better -> negative\n",
    "    discount_norm = minmax_norm(grp[\"mean_discount\"].fillna(0.0))\n",
    "\n",
    "    # Composite score for tails\n",
    "    grp[\"score_tails\"] = (\n",
    "        0.4 * orders_norm +\n",
    "        0.3 * wet_trays_norm +\n",
    "        0.2 * rows_norm -\n",
    "        0.1 * discount_norm\n",
    "    )\n",
    "\n",
    "    # Recover representative fields per item_key (first value)\n",
    "    rep_cols = df.groupby(\"item_key\").agg({\n",
    "        \"pet_food_tier\": \"first\",\n",
    "        \"wet_tray_size_clean\": \"first\",\n",
    "        \"pet_breed_size\": \"first\",\n",
    "        \"pet_life_stage_at_order\": \"first\"\n",
    "    }).reset_index()\n",
    "\n",
    "    simple = grp.merge(rep_cols, on=\"item_key\", how=\"left\")\n",
    "\n",
    "    # Build final table\n",
    "    simple[\"source\"] = \"tails\"\n",
    "    simple[\"category\"] = simple[\"pet_food_tier\"]\n",
    "    simple[\"pet_type\"] = np.nan          # unknown here\n",
    "    simple[\"pet_size\"] = simple[\"pet_breed_size\"]\n",
    "    simple[\"price\"] = np.nan             # not given directly\n",
    "    simple[\"rating_raw\"] = np.nan        # no explicit rating\n",
    "\n",
    "    simple[\"title_or_name\"] = (\n",
    "        \"Tails \" + simple[\"pet_food_tier\"].astype(str) +\n",
    "        \" \" + simple[\"wet_tray_size_clean\"].astype(str) +\n",
    "        \" (\" + simple[\"pet_life_stage_at_order\"].astype(str) +\n",
    "        \", \" + simple[\"pet_breed_size\"].astype(str) + \")\"\n",
    "    )\n",
    "\n",
    "    simple = simple.rename(columns={\n",
    "        \"score_tails\": \"global_score\"\n",
    "    })\n",
    "\n",
    "    # Align with rest of schema\n",
    "    simple[\"raw_id\"] = np.nan\n",
    "\n",
    "    # Keep columns consistent + some source-specific metrics\n",
    "    cols = [\n",
    "        \"item_key\", \"source\", \"title_or_name\", \"category\",\n",
    "        \"pet_type\", \"pet_size\", \"price\", \"rating_raw\",\n",
    "        \"n_orders\", \"n_rows\", \"total_wet_trays\", \"mean_kcal\",\n",
    "        \"mean_discount\", \"global_score\", \"raw_id\"\n",
    "    ]\n",
    "    return simple[cols]\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1) PET STORE RECORDS 2020 (has sales, price, rating, re_buy)\n",
    "# -------------------------------------------------------------------\n",
    "def build_store_items():\n",
    "    path = BASE / \"pet-store-records-2020\" / \"pet_store_records_2020.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    df[\"item_key\"] = \"store_\" + df[\"product_id\"].astype(str)\n",
    "    df[\"source\"] = \"store\"\n",
    "\n",
    "    # Normalize features\n",
    "    rating_norm = df[\"rating\"] / 10.0  # ratings 1‚Äì10\n",
    "    sales_norm = log1p_norm(df[\"sales\"])\n",
    "    price_norm = minmax_norm(df[\"price\"])\n",
    "    rebuy_norm = df[\"re_buy\"].astype(float)  # 0 or 1\n",
    "\n",
    "    df[\"score_store\"] = (\n",
    "        0.4 * rating_norm +\n",
    "        0.35 * sales_norm +\n",
    "        0.15 * rebuy_norm -\n",
    "        0.10 * price_norm\n",
    "    )\n",
    "\n",
    "    simple = df[[\n",
    "        \"item_key\", \"source\", \"product_id\", \"product_category\",\n",
    "        \"pet_type\", \"pet_size\", \"price\", \"rating\", \"sales\", \"re_buy\",\n",
    "        \"score_store\"\n",
    "    ]].copy()\n",
    "\n",
    "    simple = simple.rename(columns={\n",
    "        \"product_id\": \"raw_id\",\n",
    "        \"product_category\": \"category\",\n",
    "        \"score_store\": \"global_score\",\n",
    "        \"rating\": \"rating_raw\"\n",
    "    })\n",
    "\n",
    "    simple[\"title_or_name\"] = (\n",
    "        \"Store \" + simple[\"category\"].astype(str) +\n",
    "        \" (\" + simple[\"pet_type\"].astype(str) + \", \" +\n",
    "        simple[\"pet_size\"].astype(str) + \")\"\n",
    "    )\n",
    "\n",
    "    return simple\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2) ALIEXPRESS (averageStar, quantity, tradeAmount, wishedCount)\n",
    "# -------------------------------------------------------------------\n",
    "def build_aliexpress_items():\n",
    "    path = BASE / \"e-commerce-pet-supplies-dataset\" / \"aliexpress_pet_supplies.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    df[\"item_key\"] = \"ali_\" + df.index.astype(str)\n",
    "    df[\"source\"] = \"aliexpress\"\n",
    "\n",
    "    df[\"avg_star\"] = df[\"averageStar\"].astype(float)\n",
    "    df[\"trade_num\"] = to_numeric_series(df[\"tradeAmount\"])\n",
    "    df[\"wished\"] = df[\"wishedCount\"].astype(float)\n",
    "    df[\"quantity\"] = df[\"quantity\"].astype(float)\n",
    "\n",
    "    # Normalize\n",
    "    star_norm = minmax_norm(df[\"avg_star\"])\n",
    "    trade_norm = log1p_norm(df[\"trade_num\"])\n",
    "    wish_norm = log1p_norm(df[\"wished\"])\n",
    "    qty_norm = log1p_norm(df[\"quantity\"])\n",
    "\n",
    "    df[\"score_ali\"] = (\n",
    "        0.45 * star_norm +\n",
    "        0.30 * trade_norm +\n",
    "        0.15 * wish_norm +\n",
    "        0.10 * qty_norm\n",
    "    )\n",
    "\n",
    "    simple = df[[\n",
    "        \"item_key\", \"source\", \"title\",\n",
    "        \"avg_star\", \"trade_num\", \"wished\", \"quantity\", \"score_ali\"\n",
    "    ]].copy()\n",
    "\n",
    "    simple = simple.rename(columns={\n",
    "        \"title\": \"title_or_name\",\n",
    "        \"score_ali\": \"global_score\"\n",
    "    })\n",
    "\n",
    "    # Map avg_star as rating_raw (so we have a common rating column)\n",
    "    simple[\"rating_raw\"] = simple[\"avg_star\"]\n",
    "\n",
    "    # Other standard fields\n",
    "    simple[\"price\"] = np.nan\n",
    "    simple[\"category\"] = np.nan\n",
    "    simple[\"pet_type\"] = np.nan\n",
    "    simple[\"pet_size\"] = np.nan\n",
    "    simple[\"raw_id\"] = np.nan\n",
    "\n",
    "    return simple\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3) CHEWY (average_rating, reviews_count, Price)\n",
    "# -------------------------------------------------------------------\n",
    "def build_chewy_items():\n",
    "    path = BASE / \"chewy-data\" / \"chewy_scraper_sample.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    df[\"item_key\"] = \"chewy_\" + df[\"sku\"].astype(str)\n",
    "    df[\"source\"] = \"chewy\"\n",
    "\n",
    "    df[\"price_val\"] = to_numeric_series(df[\"Price\"])\n",
    "    df[\"rating_val\"] = df[\"average_rating\"].astype(float)\n",
    "    df[\"reviews_val\"] = df[\"reviews_count\"].fillna(0).astype(float)\n",
    "\n",
    "    rating_norm = minmax_norm(df[\"rating_val\"])\n",
    "    reviews_norm = log1p_norm(df[\"reviews_val\"])\n",
    "    price_norm = minmax_norm(df[\"price_val\"])\n",
    "\n",
    "    df[\"score_chewy\"] = (\n",
    "        0.5 * rating_norm +\n",
    "        0.35 * reviews_norm -\n",
    "        0.15 * price_norm\n",
    "    )\n",
    "\n",
    "    simple = df[[\n",
    "        \"item_key\", \"source\", \"name\", \"brand\", \"breadcrumb\",\n",
    "        \"price_val\", \"rating_val\", \"reviews_val\", \"score_chewy\"\n",
    "    ]].copy()\n",
    "\n",
    "    simple = simple.rename(columns={\n",
    "        \"name\": \"title_or_name\",\n",
    "        \"price_val\": \"price\",\n",
    "        \"rating_val\": \"rating_raw\",\n",
    "        \"score_chewy\": \"global_score\",\n",
    "        \"breadcrumb\": \"category\"\n",
    "    })\n",
    "\n",
    "    simple[\"pet_type\"] = np.nan\n",
    "    simple[\"pet_size\"] = np.nan\n",
    "    simple[\"raw_id\"] = df[\"sku\"].astype(str)\n",
    "\n",
    "    return simple\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4) AMAZON (only price & brand; no rating in sample)\n",
    "# -------------------------------------------------------------------\n",
    "def build_amazon_items():\n",
    "    path = BASE / \"amazon-pet-supplies-data\" / \"amazon_pet_supplies_dataset_sample.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    df[\"item_key\"] = \"amz_\" + df[\"asin\"].astype(str)\n",
    "    df[\"source\"] = \"amazon\"\n",
    "\n",
    "    df[\"price_val\"] = to_numeric_series(df[\"price\"])\n",
    "    rating = pd.Series(np.zeros(len(df)), index=df.index, dtype=float)\n",
    "\n",
    "    price_norm = minmax_norm(df[\"price_val\"])\n",
    "    rating_norm = rating  # all zeros\n",
    "\n",
    "    df[\"score_amz\"] = (\n",
    "        0.2 * rating_norm -\n",
    "        0.8 * price_norm\n",
    "    )\n",
    "\n",
    "    simple = df[[\n",
    "        \"item_key\", \"source\", \"title\", \"brand\",\n",
    "        \"breadcrumbs\", \"price_val\", \"score_amz\"\n",
    "    ]].copy()\n",
    "\n",
    "    simple = simple.rename(columns={\n",
    "        \"title\": \"title_or_name\",\n",
    "        \"price_val\": \"price\",\n",
    "        \"score_amz\": \"global_score\",\n",
    "        \"breadcrumbs\": \"category\"\n",
    "    })\n",
    "\n",
    "    simple[\"rating_raw\"] = rating\n",
    "    simple[\"pet_type\"] = np.nan\n",
    "    simple[\"pet_size\"] = np.nan\n",
    "    simple[\"raw_id\"] = df[\"asin\"].astype(str)\n",
    "\n",
    "    return simple\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 5) Build one unified item table (ALL SOURCES)\n",
    "# -------------------------------------------------------------------\n",
    "def build_item_only_catalog():\n",
    "    tails_items = build_tails_items()\n",
    "    store_items = build_store_items()\n",
    "    ali_items = build_aliexpress_items()\n",
    "    chewy_items = build_chewy_items()\n",
    "    amz_items = build_amazon_items()\n",
    "\n",
    "    all_items = pd.concat(\n",
    "        [tails_items, store_items, ali_items, chewy_items, amz_items],\n",
    "        ignore_index=True,\n",
    "        sort=False\n",
    "    )\n",
    "\n",
    "    # Re-normalize global_score within each source\n",
    "    all_items[\"source_score_norm\"] = (\n",
    "        all_items.groupby(\"source\")[\"global_score\"]\n",
    "        .transform(lambda x: minmax_norm(x))\n",
    "    )\n",
    "\n",
    "    # Final combined score: 50% global_score, 50% source-normalized\n",
    "    all_items[\"final_score\"] = (\n",
    "        0.5 * minmax_norm(all_items[\"global_score\"]) +\n",
    "        0.5 * all_items[\"source_score_norm\"]\n",
    "    )\n",
    "\n",
    "    return all_items\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 6) Recommendation functions (no users; just item ranking)\n",
    "# -------------------------------------------------------------------\n",
    "class ItemOnlyRecommender:\n",
    "    \"\"\"\n",
    "    No user dimension: just rank items by final_score.\n",
    "    You can filter by source, price, pet_type, etc.\n",
    "    \"\"\"\n",
    "    def __init__(self, items_df: pd.DataFrame):\n",
    "        self.items = items_df.copy()\n",
    "        self.items = self.items.replace([np.inf, -np.inf], np.nan)\n",
    "        self.items[\"final_score\"] = self.items[\"final_score\"].fillna(0.0)\n",
    "\n",
    "    def recommend_global(\n",
    "        self,\n",
    "        N: int = 10,\n",
    "        source: str | None = None,\n",
    "        max_price: float | None = None,\n",
    "        pet_type: str | None = None\n",
    "    ) -> pd.DataFrame:\n",
    "        df = self.items\n",
    "\n",
    "        if source is not None:\n",
    "            df = df[df[\"source\"] == source]\n",
    "\n",
    "        if max_price is not None:\n",
    "            df = df[(df[\"price\"].notna()) & (df[\"price\"] <= max_price)]\n",
    "\n",
    "        if pet_type is not None:\n",
    "            pt = pet_type.lower()\n",
    "            mask = (\n",
    "                df[\"pet_type\"].fillna(\"\").str.lower().str.contains(pt) |\n",
    "                df[\"category\"].fillna(\"\").str.lower().str.contains(pt) |\n",
    "                df[\"title_or_name\"].fillna(\"\").str.lower().str.contains(pt)\n",
    "            )\n",
    "            df = df[mask]\n",
    "\n",
    "        df = df.sort_values(\"final_score\", ascending=False)\n",
    "        return df.head(N).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 7) Example usage\n",
    "# -------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    items_catalog = build_item_only_catalog()\n",
    "    print(\"Unified item-only catalog:\", items_catalog.shape)\n",
    "    print(items_catalog.head(5)[[\n",
    "        \"item_key\", \"source\", \"title_or_name\",\n",
    "        \"price\", \"rating_raw\", \"global_score\", \"final_score\"\n",
    "    ]])\n",
    "\n",
    "    recsys = ItemOnlyRecommender(items_catalog)\n",
    "\n",
    "    print(\"\\n=== TOP 10 GLOBAL ITEMS (all sources) ===\")\n",
    "    print(\n",
    "        recsys.recommend_global(N=10)[[\n",
    "            \"item_key\", \"source\", \"title_or_name\",\n",
    "            \"price\", \"rating_raw\", \"final_score\"\n",
    "        ]]\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== TOP 5 CHEAP STORE ITEMS FOR DOGS (price <= 10000) ===\")\n",
    "    print(\n",
    "        recsys.recommend_global(\n",
    "            N=5, source=\"store\", pet_type=\"dog\", max_price=10000\n",
    "        )[\n",
    "            [\"item_key\", \"title_or_name\", \"price\",\n",
    "             \"rating_raw\", \"sales\", \"re_buy\", \"final_score\"]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== TOP 5 ALIEXPRESS ITEMS ===\")\n",
    "    print(\n",
    "        recsys.recommend_global(N=5, source=\"aliexpress\")[\n",
    "            [\"item_key\", \"source\", \"title_or_name\",\n",
    "             \"rating_raw\", \"trade_num\", \"wished\", \"quantity\", \"final_score\"]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== TOP 5 TAILS ITEMS ===\")\n",
    "    print(\n",
    "        recsys.recommend_global(N=5, source=\"tails\")[\n",
    "            [\"item_key\", \"title_or_name\",\n",
    "             \"n_orders\", \"total_wet_trays\", \"mean_kcal\",\n",
    "             \"mean_discount\", \"final_score\"]\n",
    "        ]\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 952329,
     "sourceId": 1612927,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1136542,
     "sourceId": 1906514,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1581658,
     "sourceId": 2602579,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2367237,
     "sourceId": 3989285,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3612212,
     "sourceId": 6282117,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3790001,
     "sourceId": 6559547,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4995419,
     "sourceId": 8396863,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
